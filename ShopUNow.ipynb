{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNuCxh/Fz3kksRPCeyS1Oe/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p-disha/ShopUNow-Agent/blob/main/ShopUNow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#########################################################################################\n"
      ],
      "metadata": {
        "id": "iEqj7kzsa8Wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tech Stack\n",
        "\n",
        "* LangChain / langchain_community-\tProvides VectorStores (FAISS), Document abstraction, Embeddings, and Retrieval.\n",
        "\n",
        "\n",
        "* FAISS (vectorstore)-\tFor embedding storage & similarity search (RAG).\n",
        "Sentence-Transformers embeddings-\tTo convert document chunks into embedding vectors.\n",
        "\n",
        "\n",
        "* **pdfminer.six + pytesseract + PIL**-\tExtract text from PDFs, images (OCR) and markdown/text files — for building corpus.\n",
        "\n",
        "\n",
        "* Markdownify\tConvert markdown files to plain text.\n",
        "\n",
        "\n",
        "* LangGraph (StateGraph etc.)-\tThe agent orchestration framework: state + nodes + transitions.\n",
        "\n",
        "\n",
        "* Pydantic-\tFor structured schemas of state and tool inputs (validation, typing).\n",
        "\n",
        "\n",
        "* LLM backends- OpenAI, Gemini (if available)\tFor synthesis / general LLM responses."
      ],
      "metadata": {
        "id": "lcNx5EjDfTQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parses different document types (text, csv, pdf, image) into a corpus.**\n",
        "\n",
        "**Chunks documents into manageable pieces using RecursiveCharacterTextSplitter.**\n",
        "\n",
        "**Builds a FAISS index, persists it.**\n",
        "\n",
        "**Sets up intent routing + tools for order status, returns, tickets.**\n",
        "\n",
        "**Handles RAG retrieval + LLM synthesis with system prompt.**\n",
        "\n",
        "**Passes retriever via RunnableConfig/configurable, avoiding earlier bug.**\n",
        "\n",
        "**Good structure using StateGraph, Pydantic state schemas.**"
      ],
      "metadata": {
        "id": "e27iQa2Rezzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell A – Setup & LLM with safer secret handling\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Detect whether we are running on Render / production\n",
        "IS_RENDER = bool(os.getenv(\"PORT\") or os.getenv(\"RENDER_SERVICE_TYPE\"))\n",
        "\n",
        "# --- Dev-only dependency install (Colab / local), skipped on Render ---\n",
        "if not IS_RENDER:\n",
        "    deps = [\n",
        "        \"langchain_community\",\n",
        "        \"faiss-cpu\",\n",
        "        \"langchain-openai\",\n",
        "        \"langchain-google-genai\",\n",
        "        \"pydantic\",\n",
        "        \"typing_extensions\",\n",
        "        \"vaderSentiment\",\n",
        "        \"langgraph\",\n",
        "        \"rapidfuzz\",\n",
        "        \"flask\",\n",
        "        \"flask-cors\",\n",
        "        \"pyngrok\",\n",
        "    ]\n",
        "    try:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-qU\", *deps], check=False)\n",
        "    except Exception as ex:\n",
        "        print(\"⚠️ Dev install failed:\", ex)\n",
        "\n",
        "# --- Secrets / API key handling ---\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "GEMINI_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if not IS_RENDER:\n",
        "    # In dev/Colab, attempt to fetch from google.colab userdata\n",
        "    try:\n",
        "        from google.colab import userdata  # type: ignore\n",
        "        if not OPENAI_API_KEY:\n",
        "            OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "        if not GEMINI_API_KEY:\n",
        "            GEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "        # If found, set them to env so downstream code sees them\n",
        "        if OPENAI_API_KEY:\n",
        "            os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "        if GEMINI_API_KEY:\n",
        "            os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY\n",
        "    except Exception:\n",
        "        # Not in Colab or userdata not available\n",
        "        pass\n",
        "\n",
        "# In production / Render, require at least one key\n",
        "if IS_RENDER:\n",
        "    assert OPENAI_API_KEY or GEMINI_API_KEY, \"In production, you must set OPENAI_API_KEY or GOOGLE_API_KEY.\"\n",
        "\n",
        "# --- Minimal setup only (no heavy model or FAISS initialization here) ---\n",
        "\n",
        "# Save model name or config for later initialization\n",
        "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
        "\n",
        "def get_chat_model():\n",
        "    \"\"\"\n",
        "    Return a chat model (Gemini or OpenAI or fallback).\n",
        "    Delay imports to here to avoid import-time costs.\n",
        "    \"\"\"\n",
        "    if GEMINI_API_KEY:\n",
        "        try:\n",
        "            from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "            return ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
        "        except Exception as e:\n",
        "            print(\"Gemini init failed:\", e, flush=True)\n",
        "\n",
        "    if OPENAI_API_KEY:\n",
        "        try:\n",
        "            from langchain_openai import ChatOpenAI\n",
        "            return ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
        "        except Exception as e:\n",
        "            print(\"OpenAI init failed:\", e, flush=True)\n",
        "\n",
        "    # Fallback dummy (for dev/edge case)\n",
        "    from langchain_core.messages import HumanMessage\n",
        "    class _Mock:\n",
        "        def invoke(self, messages):\n",
        "            last = None\n",
        "            for m in reversed(messages):\n",
        "                if isinstance(m, HumanMessage):\n",
        "                    last = m\n",
        "                    break\n",
        "            return type(\"Resp\", (), {\"content\": \"[MOCK] \" + (last.content if last else \"\")})\n",
        "    print(\"Using mock LLM fallback\")\n",
        "    return _Mock()\n",
        "\n",
        "# `LLM` will be set later once backend is initialized\n",
        "LLM = None\n",
        "\n",
        "SYSTEM_POLICY = (\n",
        "    \"You are ShopUNow Assistant. Be concise and accurate. Use the internal knowledge base when possible. \"\n",
        "    \"If unable to answer, ask a clarifying question.\"\n",
        ")\n",
        "\n",
        "print(\"Cell A (setup) loaded — heavy initialization delayed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIkC2RVqCKeo",
        "outputId": "f6354bd5-aee6-4f74-c02a-9e122c5bc336"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell A (setup) loaded — heavy initialization delayed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell A.1 – Lazy Load FAQ Dataset & Build Vector Store\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import faiss\n",
        "from typing import List, Tuple\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# --- Global cache to avoid reloading repeatedly ---\n",
        "_FAQ_VECTOR_STORE = None\n",
        "_FAQ_DOCS: List[Document] = []\n",
        "_FAQ_PATH = None\n",
        "\n",
        "\n",
        "def resolve_faq_path() -> str:\n",
        "    \"\"\"\n",
        "    Resolve path to the FAQ JSONL file.\n",
        "    Supports Colab (/content), data/, or root directory.\n",
        "    \"\"\"\n",
        "    candidates = [\n",
        "        \"/content/shopunow_faqs.jsonl\",\n",
        "        os.path.join(os.getcwd(), \"data\", \"shopunow_faqs.jsonl\"),\n",
        "        os.path.join(os.getcwd(), \"shopunow_faqs.jsonl\"),\n",
        "    ]\n",
        "    for c in candidates:\n",
        "        if os.path.exists(c):\n",
        "            return c\n",
        "    raise FileNotFoundError(\"❌ shopunow_faqs.jsonl not found in common paths.\")\n",
        "\n",
        "\n",
        "def load_faq_documents(path: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Read JSONL file and parse into LangChain Documents.\n",
        "    \"\"\"\n",
        "    docs = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            try:\n",
        "                record = json.loads(line)\n",
        "                question = record.get(\"question\", \"\").strip()\n",
        "                answer = record.get(\"answer\", \"\").strip()\n",
        "                dept = record.get(\"department\", \"unknown\").strip()\n",
        "                if not question or not answer:\n",
        "                    continue\n",
        "                combined_text = f\"Q: {question}\\nA: {answer}\"\n",
        "                docs.append(\n",
        "                    Document(\n",
        "                        page_content=combined_text,\n",
        "                        metadata={\n",
        "                            \"department\": dept,\n",
        "                            \"question\": question,\n",
        "                            \"answer\": answer,\n",
        "                        },\n",
        "                    )\n",
        "                )\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"⚠️ Skipping invalid JSON line: {e}\")\n",
        "    return docs\n",
        "\n",
        "\n",
        "def build_faq_vector_store(docs: List[Document]) -> Tuple[FAISS, List[Document]]:\n",
        "    \"\"\"\n",
        "    Build FAISS vector store with normalized embeddings.\n",
        "    \"\"\"\n",
        "    if not docs:\n",
        "        raise ValueError(\"No FAQ documents to build vector store.\")\n",
        "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "    dim = len(embedding_model.embed_query(\"hello world\"))\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    store = FAISS(\n",
        "        embedding_function=embedding_model,\n",
        "        index=index,\n",
        "        docstore=InMemoryDocstore(),\n",
        "        index_to_docstore_id={},\n",
        "    )\n",
        "    ids = [f\"faq_{i+1}\" for i in range(len(docs))]\n",
        "    store.add_documents(docs, ids=ids)\n",
        "    return store, docs\n",
        "\n",
        "\n",
        "def get_faq_vector_store() -> Tuple[FAISS, List[Document]]:\n",
        "    \"\"\"\n",
        "    Lazy initializer for the FAQ vector store.\n",
        "    Returns cached instance if already built.\n",
        "    \"\"\"\n",
        "    global _FAQ_VECTOR_STORE, _FAQ_DOCS, _FAQ_PATH\n",
        "    if _FAQ_VECTOR_STORE is not None:\n",
        "        return _FAQ_VECTOR_STORE, _FAQ_DOCS\n",
        "\n",
        "    try:\n",
        "        _FAQ_PATH = resolve_faq_path()\n",
        "        _FAQ_DOCS = load_faq_documents(_FAQ_PATH)\n",
        "        _FAQ_VECTOR_STORE, _FAQ_DOCS = build_faq_vector_store(_FAQ_DOCS)\n",
        "        dept_set = {d.metadata.get(\"department\", \"unknown\") for d in _FAQ_DOCS}\n",
        "        print(f\"✅ Built vector store with {len(_FAQ_DOCS)} FAQs across {len(dept_set)} departments\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error initializing FAQ store: {e}\")\n",
        "        raise\n",
        "\n",
        "    return _FAQ_VECTOR_STORE, _FAQ_DOCS\n"
      ],
      "metadata": {
        "id": "n48dlld5MHiC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell B — Agent (lazy FAQ store, cosine/IP thresholds, escalation)\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from typing import Optional, List, Dict, Any, Literal, Tuple\n",
        "from pydantic import BaseModel, Field\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "# LangChain base types\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# 👇 IMPORTANT: uses the lazy loader you created in Cell A.1\n",
        "# make sure Cell A.1 (with get_faq_vector_store) ran before this cell\n",
        "# It returns (FAISS_store, docs_list) and caches internally.\n",
        "from __main__ import get_faq_vector_store  # if this code is in one notebook\n",
        "# If this is split across files, replace with:\n",
        "# from your_module import get_faq_vector_store\n",
        "\n",
        "# --------------------\n",
        "# Determinism (for reproducibility)\n",
        "# --------------------\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# --------------------\n",
        "# Sentiment (lazy init)\n",
        "# --------------------\n",
        "_sentiment_analyzer: Optional[SentimentIntensityAnalyzer] = None\n",
        "\n",
        "def detect_sentiment(text: str) -> Literal[\"negative\", \"neutral\", \"positive\"]:\n",
        "    global _sentiment_analyzer\n",
        "    if _sentiment_analyzer is None:\n",
        "        _sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "    if not text:\n",
        "        return \"neutral\"\n",
        "    c = _sentiment_analyzer.polarity_scores(text).get(\"compound\", 0.0)\n",
        "    if c <= -0.3:\n",
        "        return \"negative\"\n",
        "    if c >= 0.3:\n",
        "        return \"positive\"\n",
        "    return \"neutral\"\n",
        "\n",
        "# --------------------\n",
        "# Dept classifier with confidence & tie handling\n",
        "# --------------------\n",
        "DEPT_KEYWORDS: Dict[str, List[str]] = {\n",
        "    \"Orders & Returns\": [\n",
        "        \"order\", \"order status\", \"track order\", \"tracking\", \"shipment\",\n",
        "        \"delivery\", \"package\", \"where is my order\", \"cancel order\",\n",
        "        \"return\", \"refund\", \"replace\", \"exchange\", \"pickup\"\n",
        "    ],\n",
        "    \"Payments & Billing\": [\n",
        "        \"payment\", \"upi\", \"card\", \"wallet\", \"cod\", \"invoice\", \"coupon\",\n",
        "        \"billing\", \"charged\", \"charge\", \"emi\", \"price\", \"gst\"\n",
        "    ],\n",
        "    \"Customer Support\": [\n",
        "        \"support\", \"contact\", \"help\", \"issue\", \"complaint\", \"agent\",\n",
        "        \"human\", \"speak to\", \"phone\", \"call\", \"email\", \"hours\", \"timings\"\n",
        "    ],\n",
        "    \"HR & IT Helpdesk\": [\n",
        "        \"password\", \"vpn\", \"access\", \"onboarding\", \"hardware\", \"software\",\n",
        "        \"leave\", \"policy\", \"salary\", \"payroll\", \"payslip\", \"stipend\",\n",
        "        \"salary date\", \"pay date\", \"salary delayed\", \"hrms\", \"hr portal\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "def classify_department_with_confidence(user_query: str) -> Tuple[Optional[str], float, Dict[str, int]]:\n",
        "    text = (user_query or \"\").lower()\n",
        "    scores: Dict[str, int] = {}\n",
        "    for dept, kws in DEPT_KEYWORDS.items():\n",
        "        score = sum(1 for kw in kws if kw in text)\n",
        "        scores[dept] = score\n",
        "\n",
        "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_dept, top_score = sorted_scores[0]\n",
        "\n",
        "    if top_score == 0:\n",
        "        return None, 0.0, scores\n",
        "\n",
        "    # near-tie / tie guard (strict here: if second >= top, treat as ambiguous)\n",
        "    if len(sorted_scores) > 1 and sorted_scores[1][1] >= top_score:\n",
        "        return None, 0.0, scores\n",
        "\n",
        "    conf = 0.6 if top_score == 1 else (0.75 if top_score == 2 else 0.9)\n",
        "    return top_dept, conf, scores\n",
        "\n",
        "# --------------------\n",
        "# Similarity thresholds (IP/cosine)\n",
        "# --------------------\n",
        "DEPT_SIM_THRESHOLDS = {\n",
        "    \"Orders & Returns\": 0.80,\n",
        "    \"Payments & Billing\": 0.78,\n",
        "    \"Customer Support\": 0.75,\n",
        "    \"HR & IT Helpdesk\": 0.80,\n",
        "    None: 0.80,  # fallback\n",
        "}\n",
        "\n",
        "# --------------------\n",
        "# Agent state\n",
        "# --------------------\n",
        "class AgentState(BaseModel):\n",
        "    user_input: str\n",
        "    department: Optional[str] = None\n",
        "    dept_confidence: float = 0.0\n",
        "    sentiment: Optional[Literal[\"negative\",\"neutral\",\"positive\"]] = None\n",
        "    tools_used: List[str] = Field(default_factory=list)\n",
        "    retrieved: List[Dict[str, Any]] = Field(default_factory=list)\n",
        "    intent: Optional[Literal[\"rag\",\"order_status\",\"return_create\",\"ticket\",\"human_escalation\",\"unknown\"]] = None\n",
        "    answer: Optional[str] = None\n",
        "    confidence: float = 0.0   # overall answer confidence\n",
        "    reason: Optional[str] = None  # why we escalated / confidence is low\n",
        "\n",
        "# --------------------\n",
        "# Helpers\n",
        "# --------------------\n",
        "def extract_answer_text(page_content: str) -> str:\n",
        "    \"\"\"If content is 'Q: ...\\\\nA: ...', return only the A: part.\"\"\"\n",
        "    if not page_content:\n",
        "        return page_content\n",
        "    lower = page_content.lower()\n",
        "    if \"a:\" in lower:\n",
        "        idx = lower.find(\"a:\")\n",
        "        return page_content[idx+2:].strip().lstrip(\":\").strip()\n",
        "    if page_content.strip().startswith(\"Q:\"):\n",
        "        return page_content.replace(\"Q:\", \"\", 1).strip()\n",
        "    return page_content\n",
        "\n",
        "def contains_any(text: str, keywords: List[str]) -> bool:\n",
        "    low = text.lower()\n",
        "    return any(kw in low for kw in keywords)\n",
        "\n",
        "# --------------------\n",
        "# Routing\n",
        "# --------------------\n",
        "def route_intent(state: AgentState) -> Dict[str, Any]:\n",
        "    user_query = state.user_input or \"\"\n",
        "    ql = user_query.lower()\n",
        "\n",
        "    sentiment = detect_sentiment(user_query)\n",
        "    dept, dept_conf, _scores = classify_department_with_confidence(user_query)\n",
        "\n",
        "    if sentiment == \"negative\":\n",
        "        intent = \"human_escalation\"\n",
        "    elif contains_any(ql, [\"order status\", \"track order\", \"where is my order\", \"tracking\", \"shipment\", \"delivery\", \"package\"]):\n",
        "        intent = \"order_status\"\n",
        "    elif contains_any(ql, [\"return\", \"refund\", \"replace\", \"exchange\"]):\n",
        "        intent = \"rag\" if contains_any(ql, [\"policy\", \"how many\", \"days\", \"window\"]) else \"return_create\"\n",
        "    elif contains_any(ql, [\"ticket\", \"helpdesk\", \"support issue\", \"complaint\", \"problem\"]):\n",
        "        intent = \"ticket\"\n",
        "    else:\n",
        "        intent = \"rag\"\n",
        "\n",
        "    print(f\"[route_intent] input={user_query!r} -> intent={intent}, dept={dept}, dept_conf={dept_conf:.2f}, sentiment={sentiment}\")\n",
        "    return {\"intent\": intent, \"department\": dept, \"dept_confidence\": dept_conf, \"sentiment\": sentiment}\n",
        "\n",
        "# --------------------\n",
        "# Tool node (does lazy FAQ load on demand)\n",
        "# --------------------\n",
        "def _filter_by_department(results: List[Any], predicted_dept: Optional[str]) -> List[Any]:\n",
        "    if not results or not predicted_dept:\n",
        "        return results or []\n",
        "    filtered = [(doc, score) for doc, score in results if (doc.metadata or {}).get(\"department\") == predicted_dept]\n",
        "    return filtered or results\n",
        "\n",
        "def tool_node(state: AgentState) -> Dict[str, Any]:\n",
        "    intent = state.intent\n",
        "    user_query = (state.user_input or \"\").strip()\n",
        "    predicted_department = state.department\n",
        "    dept_conf = state.dept_confidence\n",
        "    print(f\"[tool_node] intent={intent}, dept={predicted_department}, dept_conf={dept_conf:.2f}, input={user_query!r}\")\n",
        "\n",
        "    # --- Direct tools ---\n",
        "    if intent == \"order_status\":\n",
        "        has_order_id = any(tok.startswith((\"ORD-\", \"ord-\")) or tok.isdigit() for tok in user_query.replace(\"#\", \" \").split())\n",
        "        if not has_order_id:\n",
        "            return {\n",
        "                \"answer\": \"To check a specific order, please share your Order ID (e.g., ORD-1234).\",\n",
        "                \"tools_used\": [\"order_status_tool\"],\n",
        "                \"confidence\": 0.65,\n",
        "                \"reason\": \"order_id_missing\",\n",
        "            }\n",
        "        return {\n",
        "            \"answer\": \"Your order is being processed and will be shipped soon.\",\n",
        "            \"tools_used\": [\"order_status_tool\"],\n",
        "            \"confidence\": 0.9,\n",
        "        }\n",
        "\n",
        "    if intent == \"return_create\":\n",
        "        return {\n",
        "            \"answer\": \"Return initiated. You will receive pickup and label details via email.\",\n",
        "            \"tools_used\": [\"return_create_tool\"],\n",
        "            \"confidence\": 0.9,\n",
        "        }\n",
        "\n",
        "    if intent == \"ticket\":\n",
        "        return {\n",
        "            \"answer\": \"A support ticket has been created. Someone will get back to you shortly.\",\n",
        "            \"tools_used\": [\"ticket_tool\"],\n",
        "            \"confidence\": 0.85,\n",
        "        }\n",
        "\n",
        "    if intent == \"human_escalation\":\n",
        "        return {\n",
        "            \"answer\": \"I’m sorry for the inconvenience. Escalating to human support — someone will reach out to you soon.\",\n",
        "            \"tools_used\": [\"escalation\"],\n",
        "            \"confidence\": 0.2,\n",
        "            \"reason\": \"negative_sentiment\",\n",
        "        }\n",
        "\n",
        "    # --- Retrieval (RAG) ---\n",
        "    if intent == \"rag\":\n",
        "        if not predicted_department or dept_conf < 0.6:\n",
        "            return {\n",
        "                \"answer\": \"Your query could relate to multiple areas. I’m escalating to human support to ensure it’s handled correctly.\",\n",
        "                \"tools_used\": [\"escalation\"],\n",
        "                \"confidence\": 0.2,\n",
        "                \"reason\": \"low_department_confidence\",\n",
        "            }\n",
        "\n",
        "        # Lazy load the FAQ store only when needed\n",
        "        try:\n",
        "            faq_vector_store, faq_documents = get_faq_vector_store()\n",
        "        except Exception as e:\n",
        "            print(f\"[tool_node] ❌ Could not initialize FAQ store: {e}\")\n",
        "            return {\n",
        "                \"answer\": \"Something went wrong while preparing the knowledge base. Escalating to human support.\",\n",
        "                \"tools_used\": [\"escalation\"],\n",
        "                \"confidence\": 0.0,\n",
        "                \"reason\": \"faq_store_init_error\",\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            results = faq_vector_store.similarity_search_with_score(user_query, k=5)\n",
        "            results = [(doc, score) for doc, score in results if doc is not None]\n",
        "            results = _filter_by_department(results, predicted_department)\n",
        "\n",
        "            if not results:\n",
        "                return {\n",
        "                    \"answer\": \"Sorry, I couldn’t find reliable information in our knowledge base. Escalating to human support.\",\n",
        "                    \"tools_used\": [\"escalation\"],\n",
        "                    \"confidence\": 0.2,\n",
        "                    \"reason\": \"no_results\",\n",
        "                }\n",
        "\n",
        "            top_doc, sim = results[0]\n",
        "            print(f\"[tool_node] Top similarity={sim:.4f}\")\n",
        "            sim_threshold = DEPT_SIM_THRESHOLDS.get(predicted_department, DEPT_SIM_THRESHOLDS[None])\n",
        "\n",
        "            if sim < sim_threshold:\n",
        "                # Fuzzy question fallback if similarity low\n",
        "                best_doc, best_fuzzy = None, 0.0\n",
        "                q_low = user_query.lower()\n",
        "                for doc in faq_documents:\n",
        "                    fs = fuzz.partial_ratio(q_low, doc.metadata.get(\"question\", \"\").lower()) / 100.0\n",
        "                    if fs > best_fuzzy:\n",
        "                        best_doc, best_fuzzy = doc, fs\n",
        "                if best_doc and best_fuzzy >= 0.92:\n",
        "                    dept_meta = best_doc.metadata.get(\"department\", \"unknown\")\n",
        "                    clean_answer = extract_answer_text(best_doc.page_content)\n",
        "                    return {\n",
        "                        \"answer\": f\"{clean_answer} (Dept: {dept_meta})\",\n",
        "                        \"tools_used\": [\"rag_fuzzy_fallback\"],\n",
        "                        \"retrieved\": [{\n",
        "                            \"question\": best_doc.metadata.get(\"question\", \"\"),\n",
        "                            \"answer\": clean_answer,\n",
        "                            \"fuzzy_score\": float(best_fuzzy),\n",
        "                            \"source\": dept_meta\n",
        "                        }],\n",
        "                        \"confidence\": float(min(0.85, best_fuzzy)),\n",
        "                        \"reason\": \"fuzzy_match_high\",\n",
        "                    }\n",
        "                return {\n",
        "                    \"answer\": \"I’m not fully confident about the answer. Escalating to human support.\",\n",
        "                    \"tools_used\": [\"escalation\"],\n",
        "                    \"confidence\": float(sim),\n",
        "                    \"reason\": \"low_similarity\",\n",
        "                }\n",
        "\n",
        "            # Good similarity → return clean answer\n",
        "            dept_meta = (top_doc.metadata or {}).get(\"department\", \"unknown\")\n",
        "            clean_answer = extract_answer_text(top_doc.page_content)\n",
        "            return {\n",
        "                \"answer\": f\"{clean_answer} (Dept: {dept_meta})\",\n",
        "                \"tools_used\": [\"rag_retrieval\"],\n",
        "                \"retrieved\": [{\n",
        "                    \"question\": top_doc.metadata.get(\"question\", \"\"),\n",
        "                    \"answer\": clean_answer,\n",
        "                    \"similarity\": float(sim),\n",
        "                    \"source\": dept_meta\n",
        "                }],\n",
        "                \"confidence\": float(sim),\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[tool_node] ❌ Retrieval error: {e}\")\n",
        "            return {\n",
        "                \"answer\": \"Something went wrong while searching. Escalating to human support.\",\n",
        "                \"tools_used\": [\"escalation\"],\n",
        "                \"confidence\": 0.0,\n",
        "                \"reason\": \"retrieval_exception\",\n",
        "            }\n",
        "\n",
        "    # Fallback\n",
        "    return {\n",
        "        \"answer\": \"Could you please rephrase your request?\",\n",
        "        \"tools_used\": [\"fallback\"],\n",
        "        \"confidence\": 0.3,\n",
        "        \"reason\": \"fallback\",\n",
        "    }\n",
        "\n",
        "# --------------------\n",
        "# Synthesis (no-op — kept for future expansion)\n",
        "# --------------------\n",
        "def synthesis_node(state: AgentState) -> Dict[str, Any]:\n",
        "    return {}\n",
        "\n",
        "# --------------------\n",
        "# Build Graph (lightweight — no FAISS work happens here)\n",
        "# --------------------\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"route\", route_intent)\n",
        "graph.add_node(\"tool\", tool_node)\n",
        "graph.add_node(\"synth\", synthesis_node)\n",
        "\n",
        "graph.add_edge(START, \"route\")\n",
        "graph.add_edge(\"route\", \"tool\")\n",
        "graph.add_edge(\"tool\", \"synth\")\n",
        "graph.add_edge(\"synth\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "app = graph.compile(checkpointer=memory)\n",
        "\n",
        "# --------------------\n",
        "# Ask wrapper\n",
        "# --------------------\n",
        "def ask(user_query: str, thread_id: Optional[str] = None) -> str:\n",
        "    if not thread_id:\n",
        "        import uuid\n",
        "        thread_id = f\"thread_{uuid.uuid4().hex}\"\n",
        "    out = app.invoke(\n",
        "        {\"user_input\": user_query},\n",
        "        config={\"configurable\": {\"thread_id\": thread_id}},\n",
        "    )\n",
        "    return out.get(\"answer\", \"No answer generated.\")\n"
      ],
      "metadata": {
        "id": "18bhUnZECRuH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell B.1 - Testing (Improved Output & Meaningful Names)\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import uuid\n",
        "from pprint import pprint\n",
        "\n",
        "# Guard: only run this in dev / notebook environments, not in production (Render)\n",
        "if os.getenv(\"RENDER_SERVICE_TYPE\") or os.getenv(\"PORT\"):\n",
        "    print(\"[Skip] Testing cell running in production environment.\")\n",
        "else:\n",
        "    test_queries = [\n",
        "        \"What are your support hours?\",\n",
        "        \"Tell me order status for order id ORD-1234\",\n",
        "        \"I want a return because the product is wrong\",\n",
        "        \"My password reset isn't working, this is frustrating\",\n",
        "        \"I submitted a complaint about a support issue\",\n",
        "        \"How do I pay with UPI?\",\n",
        "        \"How to apply for leaves?\",\n",
        "        \"what is the leave policy?\",\n",
        "        \"where is my order?\",\n",
        "        \"my order is delayed\",\n",
        "        \"whats the return polcy? how many days can i return the product?\",\n",
        "        \"how many leaves can I take?\",\n",
        "        \" how many days for rturn?\",\n",
        "        \"my retturn is delayed\",\n",
        "        \"Please replace my shirt size\",\n",
        "        \"where is my order\",\n",
        "        \"when will i get my salary\",\n",
        "        \"my salaray is delayed\",\n",
        "        \"I need help,\",  # ambiguous\n",
        "    ]\n",
        "\n",
        "    for user_query in test_queries:\n",
        "        conversation_id = f\"conv_{uuid.uuid4().hex}\"\n",
        "        try:\n",
        "            state = AgentState(user_input=user_query)\n",
        "            route_info = route_intent(state)\n",
        "            response = app.invoke(\n",
        "                {\"user_input\": user_query},\n",
        "                config={\"configurable\": {\"thread_id\": conversation_id}}\n",
        "            )\n",
        "\n",
        "            print(\"=\" * 80)\n",
        "            print(f\"🧑 User Query: {user_query}\")\n",
        "            print(f\"➡️ Intent: {route_info.get('intent')} | Dept: {route_info.get('department')} | Sentiment: {route_info.get('sentiment')}\")\n",
        "            print(f\"🤖 Agent Answer: {response.get('answer', '⚠️ No answer')}\")\n",
        "            print(f\"🛠️ Tools Used: {response.get('tools_used')}\")\n",
        "            if response.get(\"retrieved\"):\n",
        "                print(\"📄 Retrieved Context:\")\n",
        "                pprint(response[\"retrieved\"])\n",
        "            print(\"=\" * 80 + \"\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error handling test query {user_query!r}: {e}\")\n",
        "            traceback.print_exc()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL6WcVgTCuGf",
        "outputId": "0d9a953d-340c-4375-8491-6b0fa7fc2026"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[route_intent] input='What are your support hours?' -> intent=rag, dept=Customer Support, dept_conf=0.75, sentiment=positive\n",
            "[route_intent] input='What are your support hours?' -> intent=rag, dept=Customer Support, dept_conf=0.75, sentiment=positive\n",
            "[tool_node] intent=rag, dept=Customer Support, dept_conf=0.75, input='What are your support hours?'\n",
            "✅ Built vector store with 119 FAQs across 5 departments\n",
            "[tool_node] Top similarity=0.8337\n",
            "================================================================================\n",
            "🧑 User Query: What are your support hours?\n",
            "➡️ Intent: rag | Dept: Customer Support | Sentiment: positive\n",
            "🤖 Agent Answer: Yes, live chat is available from 9 AM to 9 PM IST on our website and mobile app. (Dept: Customer Support)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'Yes, live chat is available from 9 AM to 9 PM IST on our website '\n",
            "            'and mobile app.',\n",
            "  'question': 'Do you have live chat support?',\n",
            "  'similarity': 0.8337283134460449,\n",
            "  'source': 'Customer Support'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='Tell me order status for order id ORD-1234' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[route_intent] input='Tell me order status for order id ORD-1234' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[tool_node] intent=order_status, dept=Orders & Returns, dept_conf=0.75, input='Tell me order status for order id ORD-1234'\n",
            "================================================================================\n",
            "🧑 User Query: Tell me order status for order id ORD-1234\n",
            "➡️ Intent: order_status | Dept: Orders & Returns | Sentiment: neutral\n",
            "🤖 Agent Answer: Your order is being processed and will be shipped soon.\n",
            "🛠️ Tools Used: ['order_status_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='I want a return because the product is wrong' -> intent=human_escalation, dept=Orders & Returns, dept_conf=0.60, sentiment=negative\n",
            "[route_intent] input='I want a return because the product is wrong' -> intent=human_escalation, dept=Orders & Returns, dept_conf=0.60, sentiment=negative\n",
            "[tool_node] intent=human_escalation, dept=Orders & Returns, dept_conf=0.60, input='I want a return because the product is wrong'\n",
            "================================================================================\n",
            "🧑 User Query: I want a return because the product is wrong\n",
            "➡️ Intent: human_escalation | Dept: Orders & Returns | Sentiment: negative\n",
            "🤖 Agent Answer: I’m sorry for the inconvenience. Escalating to human support — someone will reach out to you soon.\n",
            "🛠️ Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input=\"My password reset isn't working, this is frustrating\" -> intent=human_escalation, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=negative\n",
            "[route_intent] input=\"My password reset isn't working, this is frustrating\" -> intent=human_escalation, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=negative\n",
            "[tool_node] intent=human_escalation, dept=HR & IT Helpdesk, dept_conf=0.60, input=\"My password reset isn't working, this is frustrating\"\n",
            "================================================================================\n",
            "🧑 User Query: My password reset isn't working, this is frustrating\n",
            "➡️ Intent: human_escalation | Dept: HR & IT Helpdesk | Sentiment: negative\n",
            "🤖 Agent Answer: I’m sorry for the inconvenience. Escalating to human support — someone will reach out to you soon.\n",
            "🛠️ Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='I submitted a complaint about a support issue' -> intent=ticket, dept=Customer Support, dept_conf=0.90, sentiment=neutral\n",
            "[route_intent] input='I submitted a complaint about a support issue' -> intent=ticket, dept=Customer Support, dept_conf=0.90, sentiment=neutral\n",
            "[tool_node] intent=ticket, dept=Customer Support, dept_conf=0.90, input='I submitted a complaint about a support issue'\n",
            "================================================================================\n",
            "🧑 User Query: I submitted a complaint about a support issue\n",
            "➡️ Intent: ticket | Dept: Customer Support | Sentiment: neutral\n",
            "🤖 Agent Answer: A support ticket has been created. Someone will get back to you shortly.\n",
            "🛠️ Tools Used: ['ticket_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='How do I pay with UPI?' -> intent=rag, dept=Payments & Billing, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='How do I pay with UPI?' -> intent=rag, dept=Payments & Billing, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=Payments & Billing, dept_conf=0.60, input='How do I pay with UPI?'\n",
            "[tool_node] Top similarity=0.8774\n",
            "================================================================================\n",
            "🧑 User Query: How do I pay with UPI?\n",
            "➡️ Intent: rag | Dept: Payments & Billing | Sentiment: neutral\n",
            "🤖 Agent Answer: At checkout, select UPI, click 'Add New ID', and complete verification. (Dept: Payments & Billing)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': \"At checkout, select UPI, click 'Add New ID', and complete \"\n",
            "            'verification.',\n",
            "  'question': 'How do I add a new UPI ID?',\n",
            "  'similarity': 0.8774329423904419,\n",
            "  'source': 'Payments & Billing'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='How to apply for leaves?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='How to apply for leaves?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, input='How to apply for leaves?'\n",
            "[tool_node] Top similarity=0.9056\n",
            "================================================================================\n",
            "🧑 User Query: How to apply for leaves?\n",
            "➡️ Intent: rag | Dept: HR & IT Helpdesk | Sentiment: neutral\n",
            "🤖 Agent Answer: You can apply for leave via the HRMS portal with manager approval. (Dept: HR & IT Helpdesk)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'You can apply for leave via the HRMS portal with manager '\n",
            "            'approval.',\n",
            "  'question': 'How to apply for leaves?',\n",
            "  'similarity': 0.9055657386779785,\n",
            "  'source': 'HR & IT Helpdesk'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='what is the leave policy?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.75, sentiment=neutral\n",
            "[route_intent] input='what is the leave policy?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.75, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=HR & IT Helpdesk, dept_conf=0.75, input='what is the leave policy?'\n",
            "[tool_node] Top similarity=0.8766\n",
            "================================================================================\n",
            "🧑 User Query: what is the leave policy?\n",
            "➡️ Intent: rag | Dept: HR & IT Helpdesk | Sentiment: neutral\n",
            "🤖 Agent Answer: Employees are entitled to 20 days of annual leave, with manager approval required. (Dept: HR & IT Helpdesk)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'Employees are entitled to 20 days of annual leave, with manager '\n",
            "            'approval required.',\n",
            "  'question': 'What is the leave policy?',\n",
            "  'similarity': 0.8765844106674194,\n",
            "  'source': 'HR & IT Helpdesk'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='where is my order?' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[route_intent] input='where is my order?' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[tool_node] intent=order_status, dept=Orders & Returns, dept_conf=0.75, input='where is my order?'\n",
            "================================================================================\n",
            "🧑 User Query: where is my order?\n",
            "➡️ Intent: order_status | Dept: Orders & Returns | Sentiment: neutral\n",
            "🤖 Agent Answer: To check a specific order, please share your Order ID (e.g., ORD-1234).\n",
            "🛠️ Tools Used: ['order_status_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='my order is delayed' -> intent=rag, dept=Orders & Returns, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='my order is delayed' -> intent=rag, dept=Orders & Returns, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=Orders & Returns, dept_conf=0.60, input='my order is delayed'\n",
            "[tool_node] Top similarity=0.8672\n",
            "================================================================================\n",
            "🧑 User Query: my order is delayed\n",
            "➡️ Intent: rag | Dept: Orders & Returns | Sentiment: neutral\n",
            "🤖 Agent Answer: If your order is delayed, please check your tracking page or contact support for assistance. (Dept: Orders & Returns)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'If your order is delayed, please check your tracking page or '\n",
            "            'contact support for assistance.',\n",
            "  'question': 'My order is delayed',\n",
            "  'similarity': 0.8672482967376709,\n",
            "  'source': 'Orders & Returns'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='whats the return polcy? how many days can i return the product?' -> intent=rag, dept=Orders & Returns, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='whats the return polcy? how many days can i return the product?' -> intent=rag, dept=Orders & Returns, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=Orders & Returns, dept_conf=0.60, input='whats the return polcy? how many days can i return the product?'\n",
            "[tool_node] Top similarity=0.8657\n",
            "================================================================================\n",
            "🧑 User Query: whats the return polcy? how many days can i return the product?\n",
            "➡️ Intent: rag | Dept: Orders & Returns | Sentiment: neutral\n",
            "🤖 Agent Answer: You can return items within 10 days of delivery for a full refund. (Dept: Orders & Returns)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'You can return items within 10 days of delivery for a full '\n",
            "            'refund.',\n",
            "  'question': 'What is the return policy?',\n",
            "  'similarity': 0.8657301664352417,\n",
            "  'source': 'Orders & Returns'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='how many leaves can I take?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='how many leaves can I take?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, input='how many leaves can I take?'\n",
            "[tool_node] Top similarity=0.8662\n",
            "================================================================================\n",
            "🧑 User Query: how many leaves can I take?\n",
            "➡️ Intent: rag | Dept: HR & IT Helpdesk | Sentiment: neutral\n",
            "🤖 Agent Answer: Employees can take up to 20 days of annual leave per year. Carryover is subject to approval. (Dept: HR & IT Helpdesk)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'Employees can take up to 20 days of annual leave per year. '\n",
            "            'Carryover is subject to approval.',\n",
            "  'question': 'How many leaves can I take?',\n",
            "  'similarity': 0.8662172555923462,\n",
            "  'source': 'HR & IT Helpdesk'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input=' how many days for rturn?' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[route_intent] input=' how many days for rturn?' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=None, dept_conf=0.00, input='how many days for rturn?'\n",
            "================================================================================\n",
            "🧑 User Query:  how many days for rturn?\n",
            "➡️ Intent: rag | Dept: None | Sentiment: neutral\n",
            "🤖 Agent Answer: Your query could relate to multiple areas. I’m escalating to human support to ensure it’s handled correctly.\n",
            "🛠️ Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='my retturn is delayed' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[route_intent] input='my retturn is delayed' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=None, dept_conf=0.00, input='my retturn is delayed'\n",
            "================================================================================\n",
            "🧑 User Query: my retturn is delayed\n",
            "➡️ Intent: rag | Dept: None | Sentiment: neutral\n",
            "🤖 Agent Answer: Your query could relate to multiple areas. I’m escalating to human support to ensure it’s handled correctly.\n",
            "🛠️ Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='Please replace my shirt size' -> intent=return_create, dept=Orders & Returns, dept_conf=0.60, sentiment=positive\n",
            "[route_intent] input='Please replace my shirt size' -> intent=return_create, dept=Orders & Returns, dept_conf=0.60, sentiment=positive\n",
            "[tool_node] intent=return_create, dept=Orders & Returns, dept_conf=0.60, input='Please replace my shirt size'\n",
            "================================================================================\n",
            "🧑 User Query: Please replace my shirt size\n",
            "➡️ Intent: return_create | Dept: Orders & Returns | Sentiment: positive\n",
            "🤖 Agent Answer: Return initiated. You will receive pickup and label details via email.\n",
            "🛠️ Tools Used: ['return_create_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='where is my order' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[route_intent] input='where is my order' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[tool_node] intent=order_status, dept=Orders & Returns, dept_conf=0.75, input='where is my order'\n",
            "================================================================================\n",
            "🧑 User Query: where is my order\n",
            "➡️ Intent: order_status | Dept: Orders & Returns | Sentiment: neutral\n",
            "🤖 Agent Answer: To check a specific order, please share your Order ID (e.g., ORD-1234).\n",
            "🛠️ Tools Used: ['order_status_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='when will i get my salary' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='when will i get my salary' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, input='when will i get my salary'\n",
            "[tool_node] Top similarity=0.7926\n",
            "================================================================================\n",
            "🧑 User Query: when will i get my salary\n",
            "➡️ Intent: rag | Dept: HR & IT Helpdesk | Sentiment: neutral\n",
            "🤖 Agent Answer: I’m not fully confident about the answer. Escalating to human support.\n",
            "🛠️ Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='my salaray is delayed' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[route_intent] input='my salaray is delayed' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=None, dept_conf=0.00, input='my salaray is delayed'\n",
            "================================================================================\n",
            "🧑 User Query: my salaray is delayed\n",
            "➡️ Intent: rag | Dept: None | Sentiment: neutral\n",
            "🤖 Agent Answer: Your query could relate to multiple areas. I’m escalating to human support to ensure it’s handled correctly.\n",
            "🛠️ Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='I need help,' -> intent=rag, dept=Customer Support, dept_conf=0.60, sentiment=positive\n",
            "[route_intent] input='I need help,' -> intent=rag, dept=Customer Support, dept_conf=0.60, sentiment=positive\n",
            "[tool_node] intent=rag, dept=Customer Support, dept_conf=0.60, input='I need help,'\n",
            "[tool_node] Top similarity=0.7489\n",
            "================================================================================\n",
            "🧑 User Query: I need help,\n",
            "➡️ Intent: rag | Dept: Customer Support | Sentiment: positive\n",
            "🤖 Agent Answer: I’m not fully confident about the answer. Escalating to human support.\n",
            "🛠️ Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell C — Flask API (Render + Colab Compatible, 10-min safe)\n",
        "# =========================\n",
        "import os\n",
        "import sys\n",
        "import traceback\n",
        "import threading\n",
        "import uuid\n",
        "import socket\n",
        "import time\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "# --- Flask setup ---\n",
        "flask_app = Flask(__name__)\n",
        "CORS(flask_app)\n",
        "\n",
        "def _debug(msg: str):\n",
        "    \"\"\"Safe logger for Colab/Render.\"\"\"\n",
        "    print(msg, flush=True)\n",
        "\n",
        "# --------------------\n",
        "# Agent bridge\n",
        "# --------------------\n",
        "def call_agent(query: str) -> str:\n",
        "    \"\"\"Route to active agent or fallback.\"\"\"\n",
        "    if \"ask\" in globals() and callable(globals()[\"ask\"]):\n",
        "        _debug(\"[AGENT] Using ask()\")\n",
        "        return globals()[\"ask\"](query)\n",
        "    for name in [\"agent_app\", \"graph_app\", \"app\"]:\n",
        "        obj = globals().get(name)\n",
        "        if hasattr(obj, \"invoke\"):\n",
        "            _debug(f\"[AGENT] Using graph '{name}'.invoke()\")\n",
        "            cfg = {\"configurable\": {\"thread_id\": f\"api-{uuid.uuid4().hex}\"}}\n",
        "            out = obj.invoke({\"user_input\": query}, config=cfg)\n",
        "            return out.get(\"answer\", \"No answer generated.\")\n",
        "    return \"⚠️ No active agent found — please check initialization.\"\n",
        "\n",
        "# --------------------\n",
        "# Routes\n",
        "# --------------------\n",
        "@flask_app.route(\"/ask\", methods=[\"POST\", \"GET\"])\n",
        "def ask_api():\n",
        "    try:\n",
        "        _debug(\"[API] /ask endpoint hit\")\n",
        "        if request.method == \"POST\":\n",
        "            data = request.get_json(silent=True) or {}\n",
        "            query = (data.get(\"query\") or \"\").strip()\n",
        "        else:\n",
        "            query = (request.args.get(\"query\") or \"\").strip()\n",
        "\n",
        "        if not query:\n",
        "            return jsonify({\"error\": \"Empty query\"}), 400\n",
        "\n",
        "        _debug(f\"[API] Query: {query!r}\")\n",
        "        answer = call_agent(query)\n",
        "        _debug(f\"[API] Answer: {answer!r}\")\n",
        "\n",
        "        return jsonify({\"query\": query, \"answer\": answer})\n",
        "    except Exception as e:\n",
        "        _debug(\"[API] ❌ Exception:\")\n",
        "        traceback.print_exc(file=sys.stdout)\n",
        "        return jsonify({\"error\": \"Internal Server Error\", \"details\": str(e)}), 500\n",
        "\n",
        "@flask_app.route(\"/\", methods=[\"GET\"])\n",
        "def home():\n",
        "    return jsonify({\"status\": \"ok\", \"message\": \"ShopUNow backend active\"})\n",
        "\n",
        "# --------------------\n",
        "# Environment detection\n",
        "# --------------------\n",
        "def _get_colab_secret(name: str):\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        return userdata.get(name)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def find_free_port(default=5000):\n",
        "    \"\"\"Find a free TCP port.\"\"\"\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.bind((\"\", 0))\n",
        "        return s.getsockname()[1]\n",
        "\n",
        "IS_RENDER = bool(os.getenv(\"RENDER_SERVICE_TYPE\") or os.getenv(\"PORT\"))\n",
        "NGROK_AUTH_TOKEN = _get_colab_secret(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "# =================================================\n",
        "# 🔹 COLAB DEV MODE (auto ngrok, background thread)\n",
        "# =================================================\n",
        "if not IS_RENDER and NGROK_AUTH_TOKEN:\n",
        "    PORT = find_free_port(5000)\n",
        "    _debug(f\"▶️ [Colab Mode] Launching Flask on port {PORT}\")\n",
        "\n",
        "    def run_flask():\n",
        "        flask_app.run(host=\"0.0.0.0\", port=PORT, debug=False, use_reloader=False)\n",
        "    threading.Thread(target=run_flask, daemon=True).start()\n",
        "\n",
        "    try:\n",
        "        from pyngrok import ngrok\n",
        "    except ImportError:\n",
        "        import subprocess\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyngrok\"], check=False)\n",
        "        from pyngrok import ngrok\n",
        "\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    try:\n",
        "        ngrok.kill()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        _debug(f\"🌐 Opening ngrok tunnel on port {PORT} …\")\n",
        "        tunnel = ngrok.connect(PORT, bind_tls=True)\n",
        "        public_url = getattr(tunnel, \"public_url\", str(tunnel))\n",
        "        _debug(f\"🚀 Backend Public URL: {public_url}\")\n",
        "\n",
        "        with open(\"/content/backend_url.txt\", \"w\") as f:\n",
        "            f.write(public_url.strip())\n",
        "        _debug(\"📁 backend_url.txt saved for frontend sync\")\n",
        "\n",
        "        print(\"\\n✅ Test locally:\")\n",
        "        print(f'curl -X POST \"{public_url}/ask\" -H \"Content-Type: application/json\" -d \\'{{\"query\": \"Hello\"}}\\'')\n",
        "    except Exception as e:\n",
        "        _debug(f\"❌ ngrok setup failed: {e}\")\n",
        "        traceback.print_exc(file=sys.stdout)\n",
        "\n",
        "# =================================================\n",
        "# 🔹 RENDER PROD MODE (Gunicorn-managed)\n",
        "# =================================================\n",
        "else:\n",
        "    PORT = int(os.environ.get(\"PORT\", 8000))\n",
        "    _debug(f\"▶️ [Render Mode] Binding Flask to 0.0.0.0:{PORT}\")\n",
        "\n",
        "    # Health wait (up to 10 min)\n",
        "    for i in range(600):  # 600s = 10min\n",
        "        try:\n",
        "            _debug(f\"[Startup Check] Iteration {i}/600 ...\")\n",
        "            time.sleep(1)\n",
        "        except KeyboardInterrupt:\n",
        "            break\n",
        "\n",
        "    # Gunicorn handles process launch — no manual .run()\n",
        "    if __name__ == \"__main__\":\n",
        "        flask_app.run(host=\"0.0.0.0\", port=PORT, debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgBZx70SRRCQ",
        "outputId": "25e311d9-f40a-402c-acd9-099937a15762"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ [Colab Mode] Launching Flask on port 38901\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:38901\n",
            " * Running on http://172.28.0.12:38901\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌐 Opening ngrok tunnel on port 38901 …\n",
            "🚀 Backend Public URL: https://68069f4b914f.ngrok-free.app\n",
            "📁 backend_url.txt saved for frontend sync\n",
            "\n",
            "✅ Test locally:\n",
            "curl -X POST \"https://68069f4b914f.ngrok-free.app/ask\" -H \"Content-Type: application/json\" -d '{\"query\": \"Hello\"}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell D — Streamlit Frontend (Colab Dev Only; Skipped in Render)\n",
        "# =========================\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# -----------------------------\n",
        "# 🚫 Skip frontend in Render\n",
        "# -----------------------------\n",
        "if os.getenv(\"RENDER_SERVICE_TYPE\") or os.getenv(\"PORT\"):\n",
        "    print(\"[Render Mode] Skipping Streamlit frontend.\")\n",
        "else:\n",
        "    print(\"▶️ [Colab Dev] Initializing Streamlit frontend…\")\n",
        "\n",
        "    # -----------------------------\n",
        "    # ✅ Ensure dependencies\n",
        "    # -----------------------------\n",
        "    try:\n",
        "        import streamlit\n",
        "        import requests\n",
        "        import pyngrok\n",
        "    except ImportError:\n",
        "        print(\"📦 Installing required frontend packages…\")\n",
        "        deps = [\"streamlit\", \"requests\", \"pyngrok\"]\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-qU\", *deps], check=False)\n",
        "        import streamlit\n",
        "        import requests\n",
        "        import pyngrok\n",
        "\n",
        "    # -----------------------------\n",
        "    # 🧠 Detect backend URL\n",
        "    # -----------------------------\n",
        "    backend_url_file = \"/content/backend_url.txt\"\n",
        "    default_api_url = \"http://127.0.0.1:5000/ask\"\n",
        "\n",
        "    if os.path.exists(backend_url_file):\n",
        "        try:\n",
        "            with open(backend_url_file, \"r\") as f:\n",
        "                url = f.read().strip()\n",
        "            if url:\n",
        "                default_api_url = url.rstrip(\"/\") + \"/ask\"\n",
        "                print(f\"✅ Backend URL found: {default_api_url}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Could not read backend_url.txt: {e}\")\n",
        "    else:\n",
        "        print(f\"⚠️ backend_url.txt not found — using {default_api_url}\")\n",
        "\n",
        "    # -----------------------------\n",
        "    # 🖋️ Generate Streamlit App\n",
        "    # -----------------------------\n",
        "    app_code = f\"\"\"\n",
        "import streamlit as st\n",
        "import requests\n",
        "\n",
        "st.set_page_config(page_title=\"ShopUNow Agent\", layout=\"centered\")\n",
        "st.title(\"🛍️ ShopUNow AI Assistant\")\n",
        "\n",
        "api_url = st.sidebar.text_input(\"Flask API URL\", value=\"{default_api_url}\")\n",
        "st.sidebar.caption(\"Update this if you have a different backend URL\")\n",
        "\n",
        "st.divider()\n",
        "st.subheader(\"💬 Chat Interface\")\n",
        "\n",
        "if \"chat\" not in st.session_state:\n",
        "    st.session_state.chat = []\n",
        "\n",
        "query = st.text_input(\"Enter your question:\")\n",
        "\n",
        "if st.button(\"Ask\"):\n",
        "    if query.strip():\n",
        "        st.session_state.chat.append((\"🧑 You\", query))\n",
        "        try:\n",
        "            resp = requests.post(api_url, json={{\"query\": query}}, timeout=25)\n",
        "            if resp.status_code == 200:\n",
        "                ans = resp.json().get(\"answer\", \"⚠️ No answer received.\")\n",
        "            else:\n",
        "                ans = f\"⚠️ HTTP {{resp.status_code}}: {{resp.text}}\"\n",
        "        except Exception as e:\n",
        "            ans = f\"⚠️ Request failed: {{e}}\"\n",
        "        st.session_state.chat.append((\"🤖 Agent\", ans))\n",
        "\n",
        "for sender, msg in st.session_state.chat:\n",
        "    st.markdown(f\"**{{sender}}:** {{msg}}\")\n",
        "\"\"\"\n",
        "\n",
        "    with open(\"app_frontend.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(app_code.strip())\n",
        "\n",
        "    # -----------------------------\n",
        "    # 🚀 Launch Streamlit (background)\n",
        "    # -----------------------------\n",
        "    def run_streamlit():\n",
        "        print(\"▶️ Starting Streamlit frontend on port 8501…\")\n",
        "        subprocess.run([\n",
        "            sys.executable, \"-m\", \"streamlit\", \"run\", \"app_frontend.py\",\n",
        "            \"--server.headless\", \"true\",\n",
        "            \"--server.port\", \"8501\",\n",
        "            \"--browser.gatherUsageStats\", \"false\"\n",
        "        ])\n",
        "\n",
        "    threading.Thread(target=run_streamlit, daemon=True).start()\n",
        "    time.sleep(5)\n",
        "\n",
        "    # -----------------------------\n",
        "    # 🌍 ngrok tunnel\n",
        "    # -----------------------------\n",
        "    try:\n",
        "        from pyngrok import ngrok\n",
        "        print(\"🌐 Launching ngrok tunnel for Streamlit (port 8501)…\")\n",
        "        tunnel = ngrok.connect(8501, bind_tls=True)\n",
        "        public_url = getattr(tunnel, \"public_url\", str(tunnel))\n",
        "        print(f\"🚀 Streamlit Public URL: {public_url}\")\n",
        "        print(\"\\n✅ Test your frontend:\")\n",
        "        print(f\"{public_url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Could not start ngrok tunnel: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgocOgNHW72d",
        "outputId": "2e0ca412-c39d-4195-9b70-72325d45288e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ [Colab Dev] Initializing Streamlit frontend…\n",
            "✅ Backend URL found: https://68069f4b914f.ngrok-free.app/ask\n",
            "▶️ Starting Streamlit frontend on port 8501…\n",
            "🌐 Launching ngrok tunnel for Streamlit (port 8501)…\n",
            "🚀 Streamlit Public URL: https://7cbfc54ed1ed.ngrok-free.app\n",
            "\n",
            "✅ Test your frontend:\n",
            "https://7cbfc54ed1ed.ngrok-free.app\n"
          ]
        }
      ]
    }
  ]
}