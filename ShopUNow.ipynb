{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpsKUC4yFNZFa53/zEaBjm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p-disha/ShopUNow-Agent/blob/main/ShopUNow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#########################################################################################\n"
      ],
      "metadata": {
        "id": "iEqj7kzsa8Wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tech Stack\n",
        "\n",
        "* LangChain / langchain_community-\tProvides VectorStores (FAISS), Document abstraction, Embeddings, and Retrieval.\n",
        "\n",
        "\n",
        "* FAISS (vectorstore)-\tFor embedding storage & similarity search (RAG).\n",
        "Sentence-Transformers embeddings-\tTo convert document chunks into embedding vectors.\n",
        "\n",
        "\n",
        "* **pdfminer.six + pytesseract + PIL**-\tExtract text from PDFs, images (OCR) and markdown/text files ‚Äî for building corpus.\n",
        "\n",
        "\n",
        "* Markdownify\tConvert markdown files to plain text.\n",
        "\n",
        "\n",
        "* LangGraph (StateGraph etc.)-\tThe agent orchestration framework: state + nodes + transitions.\n",
        "\n",
        "\n",
        "* Pydantic-\tFor structured schemas of state and tool inputs (validation, typing).\n",
        "\n",
        "\n",
        "* LLM backends- OpenAI, Gemini (if available)\tFor synthesis / general LLM responses."
      ],
      "metadata": {
        "id": "lcNx5EjDfTQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parses different document types (text, csv, pdf, image) into a corpus.**\n",
        "\n",
        "**Chunks documents into manageable pieces using RecursiveCharacterTextSplitter.**\n",
        "\n",
        "**Builds a FAISS index, persists it.**\n",
        "\n",
        "**Sets up intent routing + tools for order status, returns, tickets.**\n",
        "\n",
        "**Handles RAG retrieval + LLM synthesis with system prompt.**\n",
        "\n",
        "**Passes retriever via RunnableConfig/configurable, avoiding earlier bug.**\n",
        "\n",
        "**Good structure using StateGraph, Pydantic state schemas.**"
      ],
      "metadata": {
        "id": "e27iQa2Rezzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell A ‚Äì Setup & LLM with safer secret handling\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# -- Install dev dependencies (only in Colab/dev)\n",
        "if not os.getenv(\"RENDER_SERVICE_TYPE\") and not os.getenv(\"PORT\"):\n",
        "    deps = [\n",
        "        \"langchain_community\",\n",
        "        \"faiss-cpu\",\n",
        "        \"langchain-openai\",\n",
        "        \"langchain-google-genai\",\n",
        "        \"pydantic\",\n",
        "        \"typing_extensions\",\n",
        "        \"vaderSentiment\",\n",
        "        \"langgraph\",\n",
        "        \"rapidfuzz\",\n",
        "        \"flask\",\n",
        "        \"flask-cors\",\n",
        "        \"pyngrok\",\n",
        "    ]\n",
        "    try:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-qU\", *deps], check=False)\n",
        "    except Exception as ex:\n",
        "        print(\"‚ö†Ô∏è Dev install failed:\", ex)\n",
        "\n",
        "# -- Import core modules\n",
        "try:\n",
        "    from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "    from langchain_community.vectorstores import FAISS\n",
        "    from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "    from langchain_core.documents import Document\n",
        "    from langchain_core.messages import HumanMessage, SystemMessage\n",
        "    import faiss\n",
        "except ImportError as e:\n",
        "    raise ImportError(\n",
        "        \"Missing required LangChain integration modules. \"\n",
        "        \"Make sure `langchain-openai` and `langchain-google-genai` are installed.\"\n",
        "    ) from e\n",
        "\n",
        "# -- Try to fetch secrets from Colab user secrets if available\n",
        "openai_secret = None\n",
        "gemini_secret = None\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    openai_secret = userdata.get(\"OPENAI_API_KEY\")\n",
        "    gemini_secret = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Could not import google.colab.userdata (maybe not in Colab):\", e)\n",
        "\n",
        "# -- Set environment variables if secrets exist\n",
        "if openai_secret:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_secret\n",
        "if gemini_secret:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = gemini_secret\n",
        "\n",
        "# -- Read keys from environment now\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "GEMINI_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# -- Assertion: require at least one key in production (not in dev)\n",
        "if os.getenv(\"PORT\") or os.getenv(\"RENDER_SERVICE_TYPE\"):\n",
        "    # In Render / production\n",
        "    assert OPENAI_API_KEY or GEMINI_API_KEY, (\n",
        "        \"In production, you must set OPENAI_API_KEY or GEMINI_API_KEY.\"\n",
        "    )\n",
        "else:\n",
        "    # In Colab/dev: warn if none\n",
        "    if not (OPENAI_API_KEY or GEMINI_API_KEY):\n",
        "        print(\"‚ö†Ô∏è Warning: No API keys set. Some functionality may be limited.\")\n",
        "\n",
        "# -- Proceed with embeddings, vector store, etc.\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "faq_docs = [\n",
        "    Document(page_content=\"Support hours are 9 AM‚Äì9 PM IST, Monday to Saturday\", metadata={\"department\": \"Customer Support\"}),\n",
        "    Document(page_content=\"How to contact support email or phone\", metadata={\"department\": \"Customer Support\"}),\n",
        "    Document(page_content=\"Return window is 10 days from delivery\", metadata={\"department\": \"Orders & Returns\"}),\n",
        "    Document(page_content=\"How can I initiate a return process\", metadata={\"department\": \"Orders & Returns\"}),\n",
        "    Document(page_content=\"We accept UPI, credit cards, wallets, and COD\", metadata={\"department\": \"Payments & Billing\"}),\n",
        "    Document(page_content=\"How to apply coupon at checkout\", metadata={\"department\": \"Payments & Billing\"})\n",
        "]\n",
        "\n",
        "dim = len(embeddings.embed_query(\"hello world\"))\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "vector_store = FAISS(\n",
        "    embedding_function=embeddings,\n",
        "    index=index,\n",
        "    docstore=InMemoryDocstore({}),\n",
        "    index_to_docstore_id={}\n",
        ")\n",
        "ids = [f\"doc{i+1}\" for i in range(len(faq_docs))]\n",
        "vector_store.add_documents(documents=faq_docs, ids=ids)\n",
        "\n",
        "def get_chat_model():\n",
        "    if GEMINI_API_KEY:\n",
        "        try:\n",
        "            print(\"Using Gemini LLM\")\n",
        "            return ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
        "        except Exception as e:\n",
        "            print(\"Gemini init failed:\", e)\n",
        "    if OPENAI_API_KEY:\n",
        "        try:\n",
        "            print(\"Using OpenAI model\")\n",
        "            return ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
        "        except Exception as e:\n",
        "            print(\"OpenAI init failed:\", e)\n",
        "    class _Mock:\n",
        "        def invoke(self, messages):\n",
        "            last_user = None\n",
        "            for m in reversed(messages):\n",
        "                if isinstance(m, HumanMessage):\n",
        "                    last_user = m\n",
        "                    break\n",
        "            return type(\"Resp\", (), {\"content\": \"[MOCK] \" + (last_user.content if last_user else \"\")})\n",
        "    print(\"Using mock LLM fallback\")\n",
        "    return _Mock()\n",
        "\n",
        "LLM = get_chat_model()\n",
        "\n",
        "SYSTEM_POLICY = (\n",
        "    \"You are ShopUNow Assistant. Be concise and accurate. Use the internal knowledge base when possible. \"\n",
        "    \"If unable to answer, ask a clarifying question.\"\n",
        ")\n",
        "\n",
        "print(\"Cell A setup complete: vector store and LLM initialised.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIkC2RVqCKeo",
        "outputId": "7aeae56d-8f56-46ee-c09a-fa680966fc26"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Gemini LLM\n",
            "Cell A setup complete: vector store and LLM initialised.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell A.1 - Load FAQ Dataset & Build Vector Store\n",
        "# =========================\n",
        "import os\n",
        "import json\n",
        "import faiss\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# ---- Step 1: Determine JSONL path ----\n",
        "def resolve_faq_path():\n",
        "    colab_path = \"/content/shopunow_faqs.jsonl\"\n",
        "    if os.path.exists(colab_path):\n",
        "        return colab_path\n",
        "    # fallback to repo-based path (assuming file sits in ‚Äúdata/‚Äù or project root)\n",
        "    base = os.path.dirname(__file__) if \"__file__\" in globals() else os.getcwd()\n",
        "    candidate = os.path.join(base, \"data\", \"shopunow_faqs.jsonl\")\n",
        "    if os.path.exists(candidate):\n",
        "        return candidate\n",
        "    # fallback: try base directory\n",
        "    candidate2 = os.path.join(base, \"shopunow_faqs.jsonl\")\n",
        "    if os.path.exists(candidate2):\n",
        "        return candidate2\n",
        "    # else not found\n",
        "    return None\n",
        "\n",
        "faq_path = resolve_faq_path()\n",
        "if not faq_path:\n",
        "    raise FileNotFoundError(\n",
        "        f\"‚ùå shopunow_faqs.jsonl not found. Searched common paths.\"\n",
        "    )\n",
        "\n",
        "# ---- Step 2: Load JSONL file ----\n",
        "faq_docs = []\n",
        "with open(faq_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        try:\n",
        "            record = json.loads(line)\n",
        "            question = record.get(\"question\", \"\").strip()\n",
        "            answer = record.get(\"answer\", \"\").strip()\n",
        "            dept = record.get(\"department\", \"unknown\").strip()\n",
        "            combined_text = f\"Q: {question}\\\\nA: {answer}\"\n",
        "            faq_docs.append(\n",
        "                Document(\n",
        "                    page_content=combined_text,\n",
        "                    metadata={\"department\": dept, \"question\": question, \"answer\": answer}\n",
        "                )\n",
        "            )\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"‚ö†Ô∏è Skipping bad line (invalid JSON): {line[:80]} ‚Ä¶ | {e}\")\n",
        "\n",
        "print(f\"Loaded {len(faq_docs)} FAQs from {faq_path}\")\n",
        "\n",
        "# ---- Step 3: Build FAISS Vector Store ----\n",
        "try:\n",
        "    embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Failed to initialize embeddings: {e}\")\n",
        "\n",
        "# compute dim\n",
        "dim = len(embedding_model.embed_query(\"hello world\"))\n",
        "faiss_index = faiss.IndexFlatIP(dim)\n",
        "\n",
        "faq_vector_store = FAISS(\n",
        "    embedding_function=embedding_model,\n",
        "    index=faiss_index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={}\n",
        ")\n",
        "\n",
        "faq_ids = [f\"faq_{i+1}\" for i in range(len(faq_docs))]\n",
        "faq_vector_store.add_documents(documents=faq_docs, ids=faq_ids)\n",
        "\n",
        "dept_set = {d.metadata.get(\"department\", \"unknown\") for d in faq_docs}\n",
        "print(f\"‚úÖ Vector store built with {len(faq_docs)} FAQs across {len(dept_set)} departments\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n48dlld5MHiC",
        "outputId": "b7ee1c58-3240-4040-8276-11f2c3e94e0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 119 FAQs from /content/shopunow_faqs.jsonl\n",
            "‚úÖ Vector store built with 119 FAQs across 5 departments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell B - Agent Definition with JSONL Vector Store\n",
        "# (cosine sim + dept thresholds + tie-aware classifier + escalation & confidence)\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import faiss\n",
        "import numpy as np\n",
        "import random\n",
        "from typing import Optional, List, Dict, Any, Literal, Tuple, Annotated\n",
        "from pydantic import BaseModel, Field\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# --------------------\n",
        "# Determinism\n",
        "# --------------------\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# --------------------\n",
        "# Load JSONL FAQs\n",
        "# --------------------\n",
        "def _resolve_jsonl_path():\n",
        "    # Try Colab default path\n",
        "    colab_path = \"/content/shopunow_faqs.jsonl\"\n",
        "    if os.path.exists(colab_path):\n",
        "        return colab_path\n",
        "    # Fallback: file located in repo (same folder as script/notebook)\n",
        "    base = os.path.dirname(__file__) if \"__file__\" in globals() else os.getcwd()\n",
        "    fallback = os.path.join(base, \"shopunow_faqs.jsonl\")\n",
        "    return fallback\n",
        "\n",
        "jsonl_path = _resolve_jsonl_path()\n",
        "faq_documents: List[Document] = []\n",
        "if os.path.exists(jsonl_path):\n",
        "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for raw in f:\n",
        "            raw = raw.strip()\n",
        "            if not raw:\n",
        "                continue\n",
        "            rec = json.loads(raw)\n",
        "            question = rec.get(\"question\", \"\").strip()\n",
        "            answer = rec.get(\"answer\", \"\").strip()\n",
        "            dept = rec.get(\"department\", \"unknown\").strip()\n",
        "            combined_text = f\"Q: {question}\\\\nA: {answer}\"\n",
        "            faq_documents.append(\n",
        "                Document(\n",
        "                    page_content=combined_text,\n",
        "                    metadata={\n",
        "                        \"department\": dept,\n",
        "                        \"question\": question,\n",
        "                        \"answer\": answer\n",
        "                    }\n",
        "                )\n",
        "            )\n",
        "    print(f\"Loaded {len(faq_documents)} FAQs from {jsonl_path}\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"FAQ JSONL file not found at {jsonl_path}\")\n",
        "\n",
        "# --------------------\n",
        "# Embeddings (cosine)\n",
        "# --------------------\n",
        "class NormalizedOpenAIEmbeddings(OpenAIEmbeddings):\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "        v = np.array(super().embed_query(text))\n",
        "        return (v / (np.linalg.norm(v) + 1e-10)).tolist()\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "        vs = np.array(super().embed_documents(texts))\n",
        "        return (vs / (np.linalg.norm(vs, axis=1, keepdims=True) + 1e-10)).tolist()\n",
        "\n",
        "embedding_model = NormalizedOpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "dim = len(embedding_model.embed_query(\"hello world\"))\n",
        "faiss_index = faiss.IndexFlatIP(dim)\n",
        "\n",
        "faq_vector_store = FAISS(\n",
        "    embedding_function=embedding_model,\n",
        "    index=faiss_index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={}\n",
        ")\n",
        "\n",
        "faq_ids = [f\"faq_{i+1}\" for i in range(len(faq_documents))]\n",
        "faq_vector_store.add_documents(documents=faq_documents, ids=faq_ids)\n",
        "\n",
        "dept_count = len(set(d.metadata.get(\"department\", \"unknown\") for d in faq_documents))\n",
        "print(f\"‚úÖ Vector store ready with {len(faq_documents)} docs across {dept_count} departments\")\n",
        "\n",
        "# --------------------\n",
        "# Sentiment\n",
        "# --------------------\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def detect_sentiment(text: str) -> Literal[\"negative\",\"neutral\",\"positive\"]:\n",
        "    if not text:\n",
        "        return \"neutral\"\n",
        "    c = sentiment_analyzer.polarity_scores(text).get(\"compound\", 0.0)\n",
        "    if c <= -0.3: return \"negative\"\n",
        "    if c >= 0.3: return \"positive\"\n",
        "    return \"neutral\"\n",
        "\n",
        "# ... (rest of your code: classify_department_with_confidence, route_intent, tool_node, synthesis_node, graph building, ask function) ...\n",
        "\n",
        "# --------------------\n",
        "# Dept classifier with confidence & tie handling\n",
        "# --------------------\n",
        "DEPT_KEYWORDS: Dict[str, List[str]] = {\n",
        "    \"Orders & Returns\": [\n",
        "        \"order\", \"order status\", \"track order\", \"tracking\", \"shipment\",\n",
        "        \"delivery\", \"package\", \"where is my order\", \"cancel order\",\n",
        "        \"return\", \"refund\", \"replace\", \"exchange\", \"pickup\"\n",
        "    ],\n",
        "    \"Payments & Billing\": [\n",
        "        \"payment\", \"upi\", \"card\", \"wallet\", \"cod\", \"invoice\", \"coupon\",\n",
        "        \"billing\", \"charged\", \"charge\", \"emi\", \"price\", \"gst\"\n",
        "    ],\n",
        "    \"Customer Support\": [\n",
        "        \"support\", \"contact\", \"help\", \"issue\", \"complaint\", \"agent\",\n",
        "        \"human\", \"speak to\", \"phone\", \"call\", \"email\", \"hours\", \"timings\"\n",
        "    ],\n",
        "    \"HR & IT Helpdesk\": [\n",
        "        \"password\", \"vpn\", \"access\", \"onboarding\", \"hardware\", \"software\",\n",
        "        \"leave\", \"policy\", \"salary\", \"payroll\", \"payslip\", \"stipend\",\n",
        "        \"salary date\", \"pay date\", \"salary delayed\", \"hrms\", \"hr portal\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "def classify_department_with_confidence(user_query: str) -> Tuple[Optional[str], float, Dict[str, int]]:\n",
        "    text = (user_query or \"\").lower()\n",
        "    scores: Dict[str, int] = {}\n",
        "    for dept, kws in DEPT_KEYWORDS.items():\n",
        "        score = sum(1 for kw in kws if kw in text)\n",
        "        scores[dept] = score\n",
        "\n",
        "    # rank by score\n",
        "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_dept, top_score = sorted_scores[0]\n",
        "\n",
        "    # if nothing matched\n",
        "    if top_score == 0:\n",
        "        return None, 0.0, scores\n",
        "\n",
        "    # tie or near-tie? (within 1 point of second place)\n",
        "    if len(sorted_scores) > 1 and sorted_scores[1][1] >= top_score - 0.0:\n",
        "        return None, 0.0, scores\n",
        "\n",
        "    conf = 0.6 if top_score == 1 else (0.75 if top_score == 2 else 0.9)\n",
        "    return top_dept, conf, scores\n",
        "\n",
        "# --------------------\n",
        "# Thresholds (cosine)\n",
        "# --------------------\n",
        "DEPT_SIM_THRESHOLDS = {\n",
        "    \"Orders & Returns\": 0.80,\n",
        "    \"Payments & Billing\": 0.78,\n",
        "    \"Customer Support\": 0.75,\n",
        "    \"HR & IT Helpdesk\": 0.80,  # ‚úÖ raised threshold for HR queries\n",
        "    None: 0.80,\n",
        "}\n",
        "\n",
        "# --------------------\n",
        "# Agent state, helpers, routing, tool_node, synthesis, graph, ask...\n",
        "\n",
        "# --------------------\n",
        "# Agent state\n",
        "# --------------------\n",
        "class AgentState(BaseModel):\n",
        "    user_input: str\n",
        "    department: Optional[str] = None\n",
        "    dept_confidence: float = 0.0\n",
        "    sentiment: Optional[Literal[\"negative\",\"neutral\",\"positive\"]] = None\n",
        "    tools_used: List[str] = Field(default_factory=list)\n",
        "    retrieved: List[Dict[str, Any]] = Field(default_factory=list)\n",
        "    intent: Optional[Literal[\"rag\",\"order_status\",\"return_create\",\"ticket\",\"human_escalation\",\"unknown\"]] = None\n",
        "    answer: Optional[str] = None\n",
        "    confidence: float = 0.0   # overall answer confidence\n",
        "    reason: Optional[str] = None  # why we escalated / confidence is low\n",
        "\n",
        "# --------------------\n",
        "# Helpers\n",
        "# --------------------\n",
        "def extract_answer_text(page_content: str) -> str:\n",
        "    \"\"\"If content is 'Q: ...\\\\nA: ...', return only the A: part.\"\"\"\n",
        "    if not page_content:\n",
        "        return page_content\n",
        "    lower = page_content.lower()\n",
        "    if \"a:\" in lower:\n",
        "        # take substring from first 'A:' onward (case-insensitive)\n",
        "        idx = lower.find(\"a:\")\n",
        "        return page_content[idx+2:].strip().lstrip(\":\").strip()\n",
        "    # fallback: if prefixed with 'Q:' then strip it\n",
        "    if page_content.strip().startswith(\"Q:\"):\n",
        "        return page_content.replace(\"Q:\", \"\", 1).strip()\n",
        "    return page_content\n",
        "\n",
        "def contains_any(text: str, keywords: List[str]) -> bool:\n",
        "    low = text.lower()\n",
        "    return any(kw in low for kw in keywords)\n",
        "\n",
        "# --------------------\n",
        "# Routing\n",
        "# --------------------\n",
        "def route_intent(state: AgentState) -> Dict[str, Any]:\n",
        "    user_query = state.user_input\n",
        "    query_lower = (user_query or \"\").lower()\n",
        "\n",
        "    sentiment = detect_sentiment(user_query)\n",
        "    dept, dept_conf, _scores = classify_department_with_confidence(user_query)\n",
        "\n",
        "    # If user is upset ‚Üí escalate\n",
        "    if sentiment == \"negative\":\n",
        "        intent = \"human_escalation\"\n",
        "    # order status\n",
        "    elif contains_any(query_lower, [\n",
        "        \"order status\", \"track order\", \"where is my order\", \"tracking\",\n",
        "        \"shipment\", \"delivery\", \"package\"\n",
        "    ]):\n",
        "        intent = \"order_status\"\n",
        "    # returns / exchanges ‚Üí either policy (RAG) or action (return_create)\n",
        "    elif contains_any(query_lower, [\"return\", \"refund\", \"replace\", \"exchange\"]):\n",
        "        if contains_any(query_lower, [\"policy\", \"how many\", \"days\", \"window\"]):\n",
        "            intent = \"rag\"\n",
        "        else:\n",
        "            intent = \"return_create\"\n",
        "    # tickets / complaints\n",
        "    elif contains_any(query_lower, [\"ticket\", \"helpdesk\", \"support issue\", \"complaint\", \"problem\"]):\n",
        "        intent = \"ticket\"\n",
        "    else:\n",
        "        intent = \"rag\"\n",
        "\n",
        "    print(f\"[route_intent] input={user_query!r} -> intent={intent}, dept={dept}, dept_conf={dept_conf:.2f}, sentiment={sentiment}\")\n",
        "    return {\"intent\": intent, \"department\": dept, \"dept_confidence\": dept_conf, \"sentiment\": sentiment}\n",
        "\n",
        "# --------------------\n",
        "# Tool node\n",
        "# --------------------\n",
        "def filter_by_department(results: List[Any], predicted_department: Optional[str]) -> List[Any]:\n",
        "    if not results:\n",
        "        return []\n",
        "    if predicted_department is None:\n",
        "        return results\n",
        "    filtered = [(doc, score) for doc, score in results\n",
        "                if (doc.metadata or {}).get(\"department\") == predicted_department]\n",
        "    return filtered or results\n",
        "\n",
        "def tool_node(state: AgentState) -> Dict[str, Any]:\n",
        "    intent = state.intent\n",
        "    user_query = state.user_input or \"\"\n",
        "    predicted_department = state.department\n",
        "    dept_conf = state.dept_confidence\n",
        "    print(f\"[tool_node] intent={intent}, dept={predicted_department}, dept_conf={dept_conf:.2f}, input={user_query!r}\")\n",
        "\n",
        "    # --- Direct tools ---\n",
        "    if intent == \"order_status\":\n",
        "        # Ask for Order ID if missing\n",
        "        has_order_id = any(tok.startswith((\"ORD-\", \"ord-\")) or tok.isdigit() for tok in user_query.replace(\"#\",\" \").split())\n",
        "        if not has_order_id:\n",
        "            return {\n",
        "                \"answer\": \"To check a specific order, please share your Order ID (e.g., ORD-1234).\",\n",
        "                \"tools_used\": [\"order_status_tool\"],\n",
        "                \"confidence\": 0.65,\n",
        "                \"reason\": \"order_id_missing\"\n",
        "            }\n",
        "        return {\n",
        "            \"answer\": \"Your order is being processed and will be shipped soon.\",\n",
        "            \"tools_used\": [\"order_status_tool\"],\n",
        "            \"confidence\": 0.9\n",
        "        }\n",
        "\n",
        "    if intent == \"return_create\":\n",
        "        return {\n",
        "            \"answer\": \"Return initiated. You will receive pickup and label details via email.\",\n",
        "            \"tools_used\": [\"return_create_tool\"],\n",
        "            \"confidence\": 0.9\n",
        "        }\n",
        "\n",
        "    if intent == \"ticket\":\n",
        "        return {\n",
        "            \"answer\": \"A support ticket has been created. Someone will get back to you shortly.\",\n",
        "            \"tools_used\": [\"ticket_tool\"],\n",
        "            \"confidence\": 0.85\n",
        "        }\n",
        "\n",
        "    if intent == \"human_escalation\":\n",
        "        return {\n",
        "            \"answer\": \"I‚Äôm sorry for the inconvenience. Escalating to human support ‚Äî someone will reach out to you soon.\",\n",
        "            \"tools_used\": [\"escalation\"],\n",
        "            \"confidence\": 0.2,\n",
        "            \"reason\": \"negative_sentiment\"\n",
        "        }\n",
        "\n",
        "    # --- Retrieval (RAG) ---\n",
        "    if intent == \"rag\":\n",
        "        # Low dept confidence ‚Üí escalate (ambiguous / multi-dept)\n",
        "        if not predicted_department or dept_conf < 0.6:\n",
        "            return {\n",
        "                \"answer\": \"Your query could relate to multiple areas. I‚Äôm escalating to human support to ensure it‚Äôs handled correctly.\",\n",
        "                \"tools_used\": [\"escalation\"],\n",
        "                \"confidence\": 0.2,\n",
        "                \"reason\": \"low_department_confidence\"\n",
        "            }\n",
        "        try:\n",
        "            results = faq_vector_store.similarity_search_with_score(user_query, k=5)\n",
        "            results = [(doc, score) for doc, score in results if doc is not None]\n",
        "            results = filter_by_department(results, predicted_department)\n",
        "\n",
        "            if not results:\n",
        "                return {\n",
        "                    \"answer\": \"Sorry, I couldn‚Äôt find reliable information in our knowledge base. Escalating to human support.\",\n",
        "                    \"tools_used\": [\"escalation\"],\n",
        "                    \"confidence\": 0.2,\n",
        "                    \"reason\": \"no_results\"\n",
        "                }\n",
        "\n",
        "            top_doc, cosine_sim = results[0]\n",
        "            print(f\"[tool_node] Top cosine similarity={cosine_sim:.4f}\")\n",
        "            sim_threshold = DEPT_SIM_THRESHOLDS.get(predicted_department, DEPT_SIM_THRESHOLDS[None])\n",
        "\n",
        "            if cosine_sim < sim_threshold:\n",
        "                # Optional fuzzy fallback ‚Äî only if very high fuzzy match\n",
        "                best_doc, best_fuzzy = None, 0.0\n",
        "                for doc in faq_documents:\n",
        "                    fs = fuzz.partial_ratio(user_query.lower(), doc.metadata.get(\"question\",\"\").lower()) / 100.0\n",
        "                    if fs > best_fuzzy:\n",
        "                        best_doc, best_fuzzy = doc, fs\n",
        "                if best_doc and best_fuzzy >= 0.92:\n",
        "                    dept_meta = best_doc.metadata.get(\"department\", \"unknown\")\n",
        "                    clean_answer = extract_answer_text(best_doc.page_content)\n",
        "                    return {\n",
        "                        \"answer\": f\"{clean_answer} (Dept: {dept_meta})\",\n",
        "                        \"tools_used\": [\"rag_fuzzy_fallback\"],\n",
        "                        \"retrieved\": [{\"question\": best_doc.metadata.get(\"question\",\"\"),\n",
        "                                       \"answer\": clean_answer,\n",
        "                                       \"fuzzy_score\": float(best_fuzzy),\n",
        "                                       \"source\": dept_meta}],\n",
        "                        \"confidence\": float(min(0.85, best_fuzzy)),\n",
        "                        \"reason\": \"fuzzy_match_high\"\n",
        "                    }\n",
        "                return {\n",
        "                    \"answer\": \"I‚Äôm not fully confident about the answer. Escalating to human support.\",\n",
        "                    \"tools_used\": [\"escalation\"],\n",
        "                    \"confidence\": float(cosine_sim),\n",
        "                    \"reason\": \"low_similarity\"\n",
        "                }\n",
        "\n",
        "            # Passed threshold ‚Üí return clean A: text\n",
        "            dept_meta = (top_doc.metadata or {}).get(\"department\", \"unknown\")\n",
        "            clean_answer = extract_answer_text(top_doc.page_content)\n",
        "            return {\n",
        "                \"answer\": f\"{clean_answer} (Dept: {dept_meta})\",\n",
        "                \"tools_used\": [\"rag_retrieval\"],\n",
        "                \"retrieved\": [{\"question\": top_doc.metadata.get(\"question\",\"\"),\n",
        "                               \"answer\": clean_answer,\n",
        "                               \"similarity\": float(cosine_sim),\n",
        "                               \"source\": dept_meta}],\n",
        "                \"confidence\": float(cosine_sim)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[tool_node] ‚ùå Retrieval error: {e}\")\n",
        "            return {\n",
        "                \"answer\": \"Something went wrong while searching. Escalating to human support.\",\n",
        "                \"tools_used\": [\"escalation\"],\n",
        "                \"confidence\": 0.0,\n",
        "                \"reason\": \"retrieval_exception\"\n",
        "            }\n",
        "\n",
        "    # Fallback\n",
        "    return {\n",
        "        \"answer\": \"Could you please rephrase your request?\",\n",
        "        \"tools_used\": [\"fallback\"],\n",
        "        \"confidence\": 0.3,\n",
        "        \"reason\": \"fallback\"\n",
        "    }\n",
        "\n",
        "# --------------------\n",
        "# Synthesis (no-op)\n",
        "# --------------------\n",
        "def synthesis_node(state: AgentState) -> Dict[str, Any]:\n",
        "    return {}\n",
        "\n",
        "# --------------------\n",
        "# Build Graph\n",
        "# --------------------\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"route\", route_intent)\n",
        "graph.add_node(\"tool\", tool_node)\n",
        "graph.add_node(\"synth\", synthesis_node)\n",
        "\n",
        "graph.add_edge(START, \"route\")\n",
        "graph.add_edge(\"route\", \"tool\")\n",
        "graph.add_edge(\"tool\", \"synth\")\n",
        "graph.add_edge(\"synth\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "app = graph.compile(checkpointer=memory)\n",
        "\n",
        "# --------------------\n",
        "# Ask wrapper (returns only text as before)\n",
        "# --------------------\n",
        "def ask(user_query: str, thread_id: Optional[str] = None) -> str:\n",
        "    if thread_id is None:\n",
        "        import uuid\n",
        "        thread_id = f\"thread_{uuid.uuid4().hex}\"\n",
        "    out = app.invoke({\"user_input\": user_query},\n",
        "                     config={\"configurable\": {\"thread_id\": thread_id}})\n",
        "    # out contains 'confidence' and 'reason' too if you need them in API\n",
        "    return out.get(\"answer\", \"No answer generated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18bhUnZECRuH",
        "outputId": "4eca91c6-3b06-4578-9ccd-f95d40780e87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 119 FAQs from /content/shopunow_faqs.jsonl\n",
            "‚úÖ Vector store ready with 119 docs across 5 departments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell B.1 - Testing (Improved Output & Meaningful Names)\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import uuid\n",
        "from pprint import pprint\n",
        "\n",
        "# Guard: only run this in dev / notebook environments, not in production (Render)\n",
        "if os.getenv(\"RENDER_SERVICE_TYPE\") or os.getenv(\"PORT\"):\n",
        "    print(\"[Skip] Testing cell running in production environment.\")\n",
        "else:\n",
        "    test_queries = [\n",
        "        \"What are your support hours?\",\n",
        "        \"Tell me order status for order id ORD-1234\",\n",
        "        \"I want a return because the product is wrong\",\n",
        "        \"My password reset isn't working, this is frustrating\",\n",
        "        \"I submitted a complaint about a support issue\",\n",
        "        \"How do I pay with UPI?\",\n",
        "        \"How to apply for leaves?\",\n",
        "        \"what is the leave policy?\",\n",
        "        \"where is my order?\",\n",
        "        \"my order is delayed\",\n",
        "        \"whats the return polcy? how many days can i return the product?\",\n",
        "        \"how many leaves can I take?\",\n",
        "        \" how many days for rturn?\",\n",
        "        \"my retturn is delayed\",\n",
        "        \"Please replace my shirt size\",\n",
        "        \"where is my order\",\n",
        "        \"when will i get my salary\",\n",
        "        \"my salaray is delayed\",\n",
        "        \"I need help,\",  # ambiguous\n",
        "    ]\n",
        "\n",
        "    for user_query in test_queries:\n",
        "        conversation_id = f\"conv_{uuid.uuid4().hex}\"\n",
        "        try:\n",
        "            state = AgentState(user_input=user_query)\n",
        "            route_info = route_intent(state)\n",
        "            response = app.invoke(\n",
        "                {\"user_input\": user_query},\n",
        "                config={\"configurable\": {\"thread_id\": conversation_id}}\n",
        "            )\n",
        "\n",
        "            print(\"=\" * 80)\n",
        "            print(f\"üßë User Query: {user_query}\")\n",
        "            print(f\"‚û°Ô∏è Intent: {route_info.get('intent')} | Dept: {route_info.get('department')} | Sentiment: {route_info.get('sentiment')}\")\n",
        "            print(f\"ü§ñ Agent Answer: {response.get('answer', '‚ö†Ô∏è No answer')}\")\n",
        "            print(f\"üõ†Ô∏è Tools Used: {response.get('tools_used')}\")\n",
        "            if response.get(\"retrieved\"):\n",
        "                print(\"üìÑ Retrieved Context:\")\n",
        "                pprint(response[\"retrieved\"])\n",
        "            print(\"=\" * 80 + \"\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error handling test query {user_query!r}: {e}\")\n",
        "            traceback.print_exc()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL6WcVgTCuGf",
        "outputId": "c040d482-cefd-4e1d-a965-9aac53505f50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[route_intent] input='What are your support hours?' -> intent=rag, dept=Customer Support, dept_conf=0.75, sentiment=positive\n",
            "[route_intent] input='What are your support hours?' -> intent=rag, dept=Customer Support, dept_conf=0.75, sentiment=positive\n",
            "[tool_node] intent=rag, dept=Customer Support, dept_conf=0.75, input='What are your support hours?'\n",
            "[tool_node] Top cosine similarity=0.8360\n",
            "================================================================================\n",
            "üßë User Query: What are your support hours?\n",
            "‚û°Ô∏è Intent: rag | Dept: Customer Support | Sentiment: positive\n",
            "ü§ñ Agent Answer: Yes, live chat is available from 9 AM to 9 PM IST on our website and mobile app. (Dept: Customer Support)\n",
            "üõ†Ô∏è Tools Used: ['rag_retrieval']\n",
            "üìÑ Retrieved Context:\n",
            "[{'answer': 'Yes, live chat is available from 9 AM to 9 PM IST on our website '\n",
            "            'and mobile app.',\n",
            "  'question': 'Do you have live chat support?',\n",
            "  'similarity': 0.8360017538070679,\n",
            "  'source': 'Customer Support'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='Tell me order status for order id ORD-1234' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[route_intent] input='Tell me order status for order id ORD-1234' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[tool_node] intent=order_status, dept=Orders & Returns, dept_conf=0.75, input='Tell me order status for order id ORD-1234'\n",
            "================================================================================\n",
            "üßë User Query: Tell me order status for order id ORD-1234\n",
            "‚û°Ô∏è Intent: order_status | Dept: Orders & Returns | Sentiment: neutral\n",
            "ü§ñ Agent Answer: Your order is being processed and will be shipped soon.\n",
            "üõ†Ô∏è Tools Used: ['order_status_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='I want a return because the product is wrong' -> intent=human_escalation, dept=Orders & Returns, dept_conf=0.60, sentiment=negative\n",
            "[route_intent] input='I want a return because the product is wrong' -> intent=human_escalation, dept=Orders & Returns, dept_conf=0.60, sentiment=negative\n",
            "[tool_node] intent=human_escalation, dept=Orders & Returns, dept_conf=0.60, input='I want a return because the product is wrong'\n",
            "================================================================================\n",
            "üßë User Query: I want a return because the product is wrong\n",
            "‚û°Ô∏è Intent: human_escalation | Dept: Orders & Returns | Sentiment: negative\n",
            "ü§ñ Agent Answer: I‚Äôm sorry for the inconvenience. Escalating to human support ‚Äî someone will reach out to you soon.\n",
            "üõ†Ô∏è Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input=\"My password reset isn't working, this is frustrating\" -> intent=human_escalation, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=negative\n",
            "[route_intent] input=\"My password reset isn't working, this is frustrating\" -> intent=human_escalation, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=negative\n",
            "[tool_node] intent=human_escalation, dept=HR & IT Helpdesk, dept_conf=0.60, input=\"My password reset isn't working, this is frustrating\"\n",
            "================================================================================\n",
            "üßë User Query: My password reset isn't working, this is frustrating\n",
            "‚û°Ô∏è Intent: human_escalation | Dept: HR & IT Helpdesk | Sentiment: negative\n",
            "ü§ñ Agent Answer: I‚Äôm sorry for the inconvenience. Escalating to human support ‚Äî someone will reach out to you soon.\n",
            "üõ†Ô∏è Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='I submitted a complaint about a support issue' -> intent=ticket, dept=Customer Support, dept_conf=0.90, sentiment=neutral\n",
            "[route_intent] input='I submitted a complaint about a support issue' -> intent=ticket, dept=Customer Support, dept_conf=0.90, sentiment=neutral\n",
            "[tool_node] intent=ticket, dept=Customer Support, dept_conf=0.90, input='I submitted a complaint about a support issue'\n",
            "================================================================================\n",
            "üßë User Query: I submitted a complaint about a support issue\n",
            "‚û°Ô∏è Intent: ticket | Dept: Customer Support | Sentiment: neutral\n",
            "ü§ñ Agent Answer: A support ticket has been created. Someone will get back to you shortly.\n",
            "üõ†Ô∏è Tools Used: ['ticket_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='How do I pay with UPI?' -> intent=rag, dept=Payments & Billing, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='How do I pay with UPI?' -> intent=rag, dept=Payments & Billing, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=Payments & Billing, dept_conf=0.60, input='How do I pay with UPI?'\n",
            "[tool_node] Top cosine similarity=0.8800\n",
            "================================================================================\n",
            "üßë User Query: How do I pay with UPI?\n",
            "‚û°Ô∏è Intent: rag | Dept: Payments & Billing | Sentiment: neutral\n",
            "ü§ñ Agent Answer: At checkout, select UPI, click 'Add New ID', and complete verification. (Dept: Payments & Billing)\n",
            "üõ†Ô∏è Tools Used: ['rag_retrieval']\n",
            "üìÑ Retrieved Context:\n",
            "[{'answer': \"At checkout, select UPI, click 'Add New ID', and complete \"\n",
            "            'verification.',\n",
            "  'question': 'How do I add a new UPI ID?',\n",
            "  'similarity': 0.8800431489944458,\n",
            "  'source': 'Payments & Billing'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='How to apply for leaves?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='How to apply for leaves?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, input='How to apply for leaves?'\n",
            "[tool_node] Top cosine similarity=0.9057\n",
            "================================================================================\n",
            "üßë User Query: How to apply for leaves?\n",
            "‚û°Ô∏è Intent: rag | Dept: HR & IT Helpdesk | Sentiment: neutral\n",
            "ü§ñ Agent Answer: You can apply for leave via the HRMS portal with manager approval. (Dept: HR & IT Helpdesk)\n",
            "üõ†Ô∏è Tools Used: ['rag_retrieval']\n",
            "üìÑ Retrieved Context:\n",
            "[{'answer': 'You can apply for leave via the HRMS portal with manager '\n",
            "            'approval.',\n",
            "  'question': 'How to apply for leaves?',\n",
            "  'similarity': 0.9057243466377258,\n",
            "  'source': 'HR & IT Helpdesk'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='what is the leave policy?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.75, sentiment=neutral\n",
            "[route_intent] input='what is the leave policy?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.75, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=HR & IT Helpdesk, dept_conf=0.75, input='what is the leave policy?'\n",
            "[tool_node] Top cosine similarity=0.8722\n",
            "================================================================================\n",
            "üßë User Query: what is the leave policy?\n",
            "‚û°Ô∏è Intent: rag | Dept: HR & IT Helpdesk | Sentiment: neutral\n",
            "ü§ñ Agent Answer: Employees are entitled to 20 days of annual leave, with manager approval required. (Dept: HR & IT Helpdesk)\n",
            "üõ†Ô∏è Tools Used: ['rag_retrieval']\n",
            "üìÑ Retrieved Context:\n",
            "[{'answer': 'Employees are entitled to 20 days of annual leave, with manager '\n",
            "            'approval required.',\n",
            "  'question': 'What is the leave policy?',\n",
            "  'similarity': 0.8721738457679749,\n",
            "  'source': 'HR & IT Helpdesk'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='where is my order?' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[route_intent] input='where is my order?' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[tool_node] intent=order_status, dept=Orders & Returns, dept_conf=0.75, input='where is my order?'\n",
            "================================================================================\n",
            "üßë User Query: where is my order?\n",
            "‚û°Ô∏è Intent: order_status | Dept: Orders & Returns | Sentiment: neutral\n",
            "ü§ñ Agent Answer: To check a specific order, please share your Order ID (e.g., ORD-1234).\n",
            "üõ†Ô∏è Tools Used: ['order_status_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='my order is delayed' -> intent=rag, dept=Orders & Returns, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='my order is delayed' -> intent=rag, dept=Orders & Returns, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=Orders & Returns, dept_conf=0.60, input='my order is delayed'\n",
            "[tool_node] Top cosine similarity=0.8670\n",
            "================================================================================\n",
            "üßë User Query: my order is delayed\n",
            "‚û°Ô∏è Intent: rag | Dept: Orders & Returns | Sentiment: neutral\n",
            "ü§ñ Agent Answer: If your order is delayed, please check your tracking page or contact support for assistance. (Dept: Orders & Returns)\n",
            "üõ†Ô∏è Tools Used: ['rag_retrieval']\n",
            "üìÑ Retrieved Context:\n",
            "[{'answer': 'If your order is delayed, please check your tracking page or '\n",
            "            'contact support for assistance.',\n",
            "  'question': 'My order is delayed',\n",
            "  'similarity': 0.8669788241386414,\n",
            "  'source': 'Orders & Returns'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='whats the return polcy? how many days can i return the product?' -> intent=rag, dept=Orders & Returns, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='whats the return polcy? how many days can i return the product?' -> intent=rag, dept=Orders & Returns, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=Orders & Returns, dept_conf=0.60, input='whats the return polcy? how many days can i return the product?'\n",
            "[tool_node] Top cosine similarity=0.8657\n",
            "================================================================================\n",
            "üßë User Query: whats the return polcy? how many days can i return the product?\n",
            "‚û°Ô∏è Intent: rag | Dept: Orders & Returns | Sentiment: neutral\n",
            "ü§ñ Agent Answer: You can return items within 10 days of delivery for a full refund. (Dept: Orders & Returns)\n",
            "üõ†Ô∏è Tools Used: ['rag_retrieval']\n",
            "üìÑ Retrieved Context:\n",
            "[{'answer': 'You can return items within 10 days of delivery for a full '\n",
            "            'refund.',\n",
            "  'question': 'What is the return policy?',\n",
            "  'similarity': 0.8656591773033142,\n",
            "  'source': 'Orders & Returns'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='how many leaves can I take?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='how many leaves can I take?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, input='how many leaves can I take?'\n",
            "[tool_node] Top cosine similarity=0.8656\n",
            "================================================================================\n",
            "üßë User Query: how many leaves can I take?\n",
            "‚û°Ô∏è Intent: rag | Dept: HR & IT Helpdesk | Sentiment: neutral\n",
            "ü§ñ Agent Answer: Employees can take up to 20 days of annual leave per year. Carryover is subject to approval. (Dept: HR & IT Helpdesk)\n",
            "üõ†Ô∏è Tools Used: ['rag_retrieval']\n",
            "üìÑ Retrieved Context:\n",
            "[{'answer': 'Employees can take up to 20 days of annual leave per year. '\n",
            "            'Carryover is subject to approval.',\n",
            "  'question': 'How many leaves can I take?',\n",
            "  'similarity': 0.8655785322189331,\n",
            "  'source': 'HR & IT Helpdesk'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input=' how many days for rturn?' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[route_intent] input=' how many days for rturn?' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=None, dept_conf=0.00, input=' how many days for rturn?'\n",
            "================================================================================\n",
            "üßë User Query:  how many days for rturn?\n",
            "‚û°Ô∏è Intent: rag | Dept: None | Sentiment: neutral\n",
            "ü§ñ Agent Answer: Your query could relate to multiple areas. I‚Äôm escalating to human support to ensure it‚Äôs handled correctly.\n",
            "üõ†Ô∏è Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='my retturn is delayed' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[route_intent] input='my retturn is delayed' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=None, dept_conf=0.00, input='my retturn is delayed'\n",
            "================================================================================\n",
            "üßë User Query: my retturn is delayed\n",
            "‚û°Ô∏è Intent: rag | Dept: None | Sentiment: neutral\n",
            "ü§ñ Agent Answer: Your query could relate to multiple areas. I‚Äôm escalating to human support to ensure it‚Äôs handled correctly.\n",
            "üõ†Ô∏è Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='Please replace my shirt size' -> intent=return_create, dept=Orders & Returns, dept_conf=0.60, sentiment=positive\n",
            "[route_intent] input='Please replace my shirt size' -> intent=return_create, dept=Orders & Returns, dept_conf=0.60, sentiment=positive\n",
            "[tool_node] intent=return_create, dept=Orders & Returns, dept_conf=0.60, input='Please replace my shirt size'\n",
            "================================================================================\n",
            "üßë User Query: Please replace my shirt size\n",
            "‚û°Ô∏è Intent: return_create | Dept: Orders & Returns | Sentiment: positive\n",
            "ü§ñ Agent Answer: Return initiated. You will receive pickup and label details via email.\n",
            "üõ†Ô∏è Tools Used: ['return_create_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='where is my order' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[route_intent] input='where is my order' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[tool_node] intent=order_status, dept=Orders & Returns, dept_conf=0.75, input='where is my order'\n",
            "================================================================================\n",
            "üßë User Query: where is my order\n",
            "‚û°Ô∏è Intent: order_status | Dept: Orders & Returns | Sentiment: neutral\n",
            "ü§ñ Agent Answer: To check a specific order, please share your Order ID (e.g., ORD-1234).\n",
            "üõ†Ô∏è Tools Used: ['order_status_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='when will i get my salary' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='when will i get my salary' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, input='when will i get my salary'\n",
            "[tool_node] Top cosine similarity=0.7924\n",
            "================================================================================\n",
            "üßë User Query: when will i get my salary\n",
            "‚û°Ô∏è Intent: rag | Dept: HR & IT Helpdesk | Sentiment: neutral\n",
            "ü§ñ Agent Answer: I‚Äôm not fully confident about the answer. Escalating to human support.\n",
            "üõ†Ô∏è Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='my salaray is delayed' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[route_intent] input='my salaray is delayed' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=None, dept_conf=0.00, input='my salaray is delayed'\n",
            "================================================================================\n",
            "üßë User Query: my salaray is delayed\n",
            "‚û°Ô∏è Intent: rag | Dept: None | Sentiment: neutral\n",
            "ü§ñ Agent Answer: Your query could relate to multiple areas. I‚Äôm escalating to human support to ensure it‚Äôs handled correctly.\n",
            "üõ†Ô∏è Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='I need help,' -> intent=rag, dept=Customer Support, dept_conf=0.60, sentiment=positive\n",
            "[route_intent] input='I need help,' -> intent=rag, dept=Customer Support, dept_conf=0.60, sentiment=positive\n",
            "[tool_node] intent=rag, dept=Customer Support, dept_conf=0.60, input='I need help,'\n",
            "[tool_node] Top cosine similarity=0.7517\n",
            "================================================================================\n",
            "üßë User Query: I need help,\n",
            "‚û°Ô∏è Intent: rag | Dept: Customer Support | Sentiment: positive\n",
            "ü§ñ Agent Answer: If unresolved, escalate with photos of the damaged product to escalation@shopunow.com. (Dept: Customer Support)\n",
            "üõ†Ô∏è Tools Used: ['rag_retrieval']\n",
            "üìÑ Retrieved Context:\n",
            "[{'answer': 'If unresolved, escalate with photos of the damaged product to '\n",
            "            'escalation@shopunow.com.',\n",
            "  'question': 'What if I don‚Äôt receive help for a damaged product?',\n",
            "  'similarity': 0.7517171502113342,\n",
            "  'source': 'Customer Support'}]\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell C ‚Äî Flask API (Render + Colab Compatible)\n",
        "# =========================\n",
        "import os\n",
        "import sys\n",
        "import traceback\n",
        "import threading\n",
        "import uuid\n",
        "import socket\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "# --- Flask setup ---\n",
        "flask_app = Flask(__name__)\n",
        "CORS(flask_app)\n",
        "\n",
        "def _debug(msg: str):\n",
        "    \"\"\"Safe print for Render logs.\"\"\"\n",
        "    print(msg, flush=True)\n",
        "\n",
        "# --- Core logic: agent call ---\n",
        "def call_agent(query: str) -> str:\n",
        "    \"\"\"Routes query to the appropriate agent (ask(), graph_app.invoke(), etc.)\"\"\"\n",
        "    if \"ask\" in globals() and callable(globals()[\"ask\"]):\n",
        "        _debug(\"[AGENT] Using ask()\")\n",
        "        return globals()[\"ask\"](query)\n",
        "    for name in [\"agent_app\", \"graph_app\", \"app\"]:\n",
        "        obj = globals().get(name)\n",
        "        if hasattr(obj, \"invoke\"):\n",
        "            _debug(f\"[AGENT] Using graph '{name}'.invoke()\")\n",
        "            cfg = {\"configurable\": {\"thread_id\": f\"api-{uuid.uuid4().hex}\"}}\n",
        "            out = obj.invoke({\"user_input\": query}, config=cfg)\n",
        "            return out.get(\"answer\", \"No answer generated.\")\n",
        "    return \"‚ö†Ô∏è No active agent found.\"\n",
        "\n",
        "# --- Routes ---\n",
        "@flask_app.route(\"/ask\", methods=[\"POST\", \"GET\"])\n",
        "def ask_api():\n",
        "    try:\n",
        "        _debug(\"\\n[API] ‚ñ∂Ô∏è /ask hit\")\n",
        "        query = \"\"\n",
        "        if request.method == \"POST\":\n",
        "            if not request.is_json:\n",
        "                return jsonify({\"error\": \"Content-Type must be application/json\"}), 400\n",
        "            data = request.get_json(silent=True) or {}\n",
        "            query = (data.get(\"query\") or \"\").strip()\n",
        "        else:\n",
        "            query = (request.args.get(\"query\") or \"\").strip()\n",
        "\n",
        "        if not query:\n",
        "            return jsonify({\"error\": \"Empty query\"}), 400\n",
        "\n",
        "        _debug(f\"[API] Query: {query!r}\")\n",
        "        answer = call_agent(query)\n",
        "        _debug(f\"[API] Answer: {answer!r}\")\n",
        "        return jsonify({\"query\": query, \"answer\": answer})\n",
        "\n",
        "    except Exception as e:\n",
        "        _debug(\"[API] ‚ùå internal error\")\n",
        "        traceback.print_exc(file=sys.stdout)\n",
        "        return jsonify({\"error\": \"Internal server error\", \"details\": str(e)}), 500\n",
        "\n",
        "@flask_app.route(\"/\", methods=[\"GET\"])\n",
        "def home():\n",
        "    return jsonify({\"status\": \"ok\", \"message\": \"ShopUNow backend running\"})\n",
        "\n",
        "# --- Helper: get Colab secret safely ---\n",
        "def _get_colab_secret(name: str):\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        return userdata.get(name)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def find_free_port(default=5000):\n",
        "    \"\"\"Find free port (to avoid collisions in Colab).\"\"\"\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.bind((\"\", 0))\n",
        "        return s.getsockname()[1]\n",
        "\n",
        "# --- Decide Environment ---\n",
        "IS_RENDER = bool(os.getenv(\"RENDER_SERVICE_TYPE\") or os.getenv(\"RENDER\") or os.getenv(\"PORT\"))\n",
        "NGROK_AUTH_TOKEN = _get_colab_secret(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "# =============================\n",
        "# üîπ Colab (Dev) Mode\n",
        "# =============================\n",
        "if not IS_RENDER and NGROK_AUTH_TOKEN:\n",
        "    PORT = find_free_port(5000)\n",
        "    _debug(f\"‚ñ∂Ô∏è [Colab Mode] Flask running on local port {PORT}\")\n",
        "\n",
        "    # Start Flask in background thread\n",
        "    def _run_flask():\n",
        "        flask_app.run(host=\"0.0.0.0\", port=PORT, debug=False, use_reloader=False)\n",
        "    threading.Thread(target=_run_flask, daemon=True).start()\n",
        "\n",
        "    # --- ngrok setup ---\n",
        "    try:\n",
        "        from pyngrok import ngrok\n",
        "    except ImportError:\n",
        "        import subprocess\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyngrok\"], check=False)\n",
        "        from pyngrok import ngrok\n",
        "\n",
        "    _debug(\"üîë Setting ngrok auth token...\")\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    try:\n",
        "        ngrok.kill()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        _debug(f\"üåê Starting ngrok tunnel for {PORT} ‚Ä¶\")\n",
        "        tunnel = ngrok.connect(PORT, bind_tls=True)\n",
        "        public_url = getattr(tunnel, \"public_url\", str(tunnel))\n",
        "        _debug(f\"üöÄ Public API URL: {public_url}\")\n",
        "\n",
        "        # Save for frontend\n",
        "        with open(\"/content/backend_url.txt\", \"w\") as f:\n",
        "            f.write(public_url.strip())\n",
        "        _debug(\"üìÇ backend_url.txt written\")\n",
        "\n",
        "        print(\"\\n‚úÖ Test your backend:\")\n",
        "        print(f'curl -X POST \"{public_url}/ask\" -H \"Content-Type: application/json\" -d \\'{{\"query\": \"Hello?\"}}\\'')\n",
        "\n",
        "    except Exception as e:\n",
        "        _debug(f\"‚ùå ngrok tunnel failed: {e}\")\n",
        "        traceback.print_exc(file=sys.stdout)\n",
        "\n",
        "# =============================\n",
        "# üîπ Render (Prod) Mode\n",
        "# =============================\n",
        "else:\n",
        "    PORT = int(os.environ.get(\"PORT\", 8000))\n",
        "    _debug(f\"‚ñ∂Ô∏è [Render Mode] Flask binding to {PORT}\")\n",
        "\n",
        "    # Do NOT auto-run Flask ‚Äî Gunicorn does that.\n",
        "    # Only run if invoked directly (useful for local dev)\n",
        "    if __name__ == \"__main__\" and not IS_RENDER:\n",
        "        _debug(\"üöÄ Starting Flask locally...\")\n",
        "        flask_app.run(host=\"0.0.0.0\", port=PORT, debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgBZx70SRRCQ",
        "outputId": "513625e2-18a0-4aad-e4ae-91abc732312b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ñ∂Ô∏è [Colab Mode] Flask running on local port 46599\n",
            " * Serving Flask app '__main__'\n",
            "üîë Setting ngrok auth token...\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:46599\n",
            " * Running on http://172.28.0.12:46599\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê Starting ngrok tunnel for 46599 ‚Ä¶\n",
            "üöÄ Public API URL: https://a99ca4ba8be3.ngrok-free.app\n",
            "üìÇ backend_url.txt written\n",
            "\n",
            "‚úÖ Test your backend:\n",
            "curl -X POST \"https://a99ca4ba8be3.ngrok-free.app/ask\" -H \"Content-Type: application/json\" -d '{\"query\": \"Hello?\"}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell D ‚Äì Streamlit Frontend (Colab dev only; skip in Render)\n",
        "# =========================\n",
        "import os\n",
        "import subprocess\n",
        "import threading\n",
        "\n",
        "# Skip frontend in Render / production environment\n",
        "if os.getenv(\"RENDER_SERVICE_TYPE\") or os.getenv(\"PORT\"):\n",
        "    print(\"[Render] Skipping Streamlit frontend cell.\")\n",
        "else:\n",
        "    # Dev / Colab mode: ensure required libs\n",
        "    try:\n",
        "        import streamlit\n",
        "        import requests\n",
        "        import pyngrok\n",
        "    except ImportError:\n",
        "        # Install if missing, but use subprocess to avoid !pip syntax\n",
        "        deps = [\"streamlit\", \"requests\", \"pyngrok\"]\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-qU\", *deps], check=False)\n",
        "\n",
        "    # Determine backend URL (auto-detect)\n",
        "    backend_url_file = \"/content/backend_url.txt\"\n",
        "    default_api_url = \"http://127.0.0.1:5000/ask\"\n",
        "    if os.path.exists(backend_url_file):\n",
        "        try:\n",
        "            with open(backend_url_file, \"r\") as f:\n",
        "                url = f.read().strip()\n",
        "            if url:\n",
        "                default_api_url = url.rstrip(\"/\") + \"/ask\"\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Could not read backend_url.txt:\", e)\n",
        "\n",
        "    # Create a Streamlit app file\n",
        "    with open(\"app_frontend.py\", \"w\") as f:\n",
        "        f.write(f\"\"\"\n",
        "import streamlit as st\n",
        "import requests\n",
        "\n",
        "st.set_page_config(page_title=\"ShopUNow Agent\", layout=\"centered\")\n",
        "st.title(\"üõçÔ∏è ShopUNow AI Assistant\")\n",
        "\n",
        "api_url = st.sidebar.text_input(\"Flask API URL\", value=\"{default_api_url}\")\n",
        "openai_key = st.sidebar.text_input(\"OpenAI API Key\", type=\"password\")\n",
        "gemini_key = st.sidebar.text_input(\"Gemini API Key\", type=\"password\")\n",
        "ngrok_token = st.sidebar.text_input(\"ngrok Auth Token\", type=\"password\")\n",
        "\n",
        "errors = []\n",
        "if not api_url.strip():\n",
        "    errors.append(\"‚ùå Flask API URL is required.\")\n",
        "if not (openai_key.strip() or gemini_key.strip()):\n",
        "    errors.append(\"‚ùå At least one model key (OpenAI or Gemini) is required.\")\n",
        "if not ngrok_token.strip():\n",
        "    errors.append(\"‚ùå ngrok Auth Token is required.\")\n",
        "\n",
        "if errors:\n",
        "    for e in errors:\n",
        "        st.sidebar.error(e)\n",
        "    st.stop()\n",
        "else:\n",
        "    st.sidebar.success(\"‚úÖ All required configuration set\")\n",
        "\n",
        "st.session_state.setdefault(\"secrets\", {{\n",
        "    \"API_URL\": api_url.strip(),\n",
        "    \"OPENAI_API_KEY\": openai_key.strip(),\n",
        "    \"GEMINI_API_KEY\": gemini_key.strip(),\n",
        "    \"NGROK_AUTH_TOKEN\": ngrok_token.strip()\n",
        "}})\n",
        "\n",
        "st.subheader(\"üí¨ Chat with ShopUNow Agent\")\n",
        "if \"chat\" not in st.session_state:\n",
        "    st.session_state.chat = []\n",
        "\n",
        "query = st.text_input(\"Enter your question:\")\n",
        "\n",
        "if st.button(\"Ask\"):\n",
        "    if query.strip():\n",
        "        st.session_state.chat.append((\"üßë You\", query))\n",
        "        try:\n",
        "            resp = requests.post(st.session_state.secrets[\"API_URL\"], json={{\"query\": query}}, timeout=20)\n",
        "            if resp.status_code == 200:\n",
        "                answer = resp.json().get(\"answer\", \"‚ö†Ô∏è No answer returned\")\n",
        "            else:\n",
        "                answer = f\"‚ö†Ô∏è Error {{resp.status_code}}: {{resp.text}}\"\n",
        "        except Exception as error:\n",
        "            answer = f\"‚ö†Ô∏è Request failed: {{error}}\"\n",
        "        st.session_state.chat.append((\"ü§ñ Agent\", answer))\n",
        "\n",
        "for sender, msg in st.session_state.chat:\n",
        "    st.markdown(f\"**{{sender}}:** {{msg}}\")\n",
        "\"\"\")\n",
        "\n",
        "    # Launch Streamlit in background\n",
        "    def run_streamlit():\n",
        "        subprocess.run(\n",
        "            [sys.executable, \"-m\", \"streamlit\", \"run\", \"app_frontend.py\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"]\n",
        "        )\n",
        "\n",
        "    threading.Thread(target=run_streamlit, daemon=True).start()\n",
        "\n",
        "    # If ngrok token is provided, start a tunnel\n",
        "    try:\n",
        "        from pyngrok import ngrok\n",
        "        print(\"üåê Starting ngrok tunnel for Streamlit frontend...\")\n",
        "        frontend_url = ngrok.connect(8501)\n",
        "        print(\"üöÄ Frontend URL:\", frontend_url)\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è Could not start frontend ngrok tunnel:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgocOgNHW72d",
        "outputId": "6b9241c6-f70a-40bd-8a08-b550d117c72f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê Starting ngrok tunnel for Streamlit frontend...\n",
            "üöÄ Frontend URL: NgrokTunnel: \"https://2549fccbaf2a.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}