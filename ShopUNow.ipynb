{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6uQYSweR/kYY4hY/PJCdf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p-disha/ShopUNow-Agent/blob/main/ShopUNow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#########################################################################################\n"
      ],
      "metadata": {
        "id": "iEqj7kzsa8Wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tech Stack\n",
        "\n",
        "* LangChain / langchain_community-\tProvides VectorStores (FAISS), Document abstraction, Embeddings, and Retrieval.\n",
        "\n",
        "\n",
        "* FAISS (vectorstore)-\tFor embedding storage & similarity search (RAG).\n",
        "Sentence-Transformers embeddings-\tTo convert document chunks into embedding vectors.\n",
        "\n",
        "\n",
        "* **pdfminer.six + pytesseract + PIL**-\tExtract text from PDFs, images (OCR) and markdown/text files — for building corpus.\n",
        "\n",
        "\n",
        "* Markdownify\tConvert markdown files to plain text.\n",
        "\n",
        "\n",
        "* LangGraph (StateGraph etc.)-\tThe agent orchestration framework: state + nodes + transitions.\n",
        "\n",
        "\n",
        "* Pydantic-\tFor structured schemas of state and tool inputs (validation, typing).\n",
        "\n",
        "\n",
        "* LLM backends- OpenAI, Gemini (if available)\tFor synthesis / general LLM responses."
      ],
      "metadata": {
        "id": "lcNx5EjDfTQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parses different document types (text, csv, pdf, image) into a corpus.**\n",
        "\n",
        "**Chunks documents into manageable pieces using RecursiveCharacterTextSplitter.**\n",
        "\n",
        "**Builds a FAISS index, persists it.**\n",
        "\n",
        "**Sets up intent routing + tools for order status, returns, tickets.**\n",
        "\n",
        "**Handles RAG retrieval + LLM synthesis with system prompt.**\n",
        "\n",
        "**Passes retriever via RunnableConfig/configurable, avoiding earlier bug.**\n",
        "\n",
        "**Good structure using StateGraph, Pydantic state schemas.**"
      ],
      "metadata": {
        "id": "e27iQa2Rezzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell A: Setup and Vector Store + LLM\n",
        "# =========================\n",
        "\n",
        "# Install required packages (include Google-GenAI integration if using Gemini)\n",
        "!pip install -qU langchain_community faiss-cpu langchain_openai langchain-google-genai pydantic typing_extensions vaderSentiment langgraph\n",
        "\n",
        "!pip install -qU flask flask-cors pyngrok\n",
        "\n",
        "\n",
        "# Imports\n",
        "import os\n",
        "from typing import List, Dict, Any, Optional, Literal\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# Make sure API keys are set\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    key = userdata.get(\"OPENAI_API_KEY\")\n",
        "    if key:\n",
        "        os.environ[\"OPENAI_API_KEY\"] = key\n",
        "    gem_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "    if gem_key:\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = gem_key\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "GEMINI_API_KEY = os.environ.get(\"GOOGLE_API_KEY\")  # for Gemini\n",
        "\n",
        "assert OPENAI_API_KEY or GEMINI_API_KEY, \"Please set OPENAI_API_KEY or GEMINI_API_KEY in environment variables.\"\n",
        "\n",
        "# Initialize embeddings (use OpenAI embeddings; you can use Gemini embeddings if you want and have the key)\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "# Sample documents / FAQ data with department metadata\n",
        "# You should expand these to 10-15 QA per department later\n",
        "faq_docs = [\n",
        "    Document(page_content=\"Support hours are 9 AM–9 PM IST, Monday to Saturday\", metadata={\"department\": \"Customer Support\"}),\n",
        "    Document(page_content=\"How to contact support email or phone\", metadata={\"department\": \"Customer Support\"}),\n",
        "    Document(page_content=\"Return window is 10 days from delivery\", metadata={\"department\": \"Orders & Returns\"}),\n",
        "    Document(page_content=\"How can I initiate a return process\", metadata={\"department\": \"Orders & Returns\"}),\n",
        "    Document(page_content=\"We accept UPI, credit cards, wallets, and COD\", metadata={\"department\": \"Payments & Billing\"}),\n",
        "    Document(page_content=\"How to apply coupon at checkout\", metadata={\"department\": \"Payments & Billing\"})\n",
        "]\n",
        "\n",
        "# Build the FAISS vector store\n",
        "import faiss\n",
        "\n",
        "# Compute embedding dimension\n",
        "dim = len(embeddings.embed_query(\"hello world\"))  # length of vector\n",
        "\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "\n",
        "vector_store = FAISS(\n",
        "    embedding_function=embeddings,\n",
        "    index=index,\n",
        "    docstore=InMemoryDocstore({}),\n",
        "    index_to_docstore_id={}\n",
        ")\n",
        "\n",
        "ids = [f\"doc{i+1}\" for i in range(len(faq_docs))]\n",
        "vector_store.add_documents(documents=faq_docs, ids=ids)\n",
        "\n",
        "# Initialize LLM (Chat model)\n",
        "def get_chat_model():\n",
        "    if GEMINI_API_KEY:\n",
        "        try:\n",
        "            print(\"Using Gemini LLM\")\n",
        "            return ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
        "        except Exception as e:\n",
        "            print(\"Gemini init failed:\", e)\n",
        "    if OPENAI_API_KEY:\n",
        "        try:\n",
        "            print(\"Using OpenAI model\")\n",
        "            return ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
        "        except Exception as e:\n",
        "            print(\"OpenAI init failed:\", e)\n",
        "    # fallback mock model\n",
        "    class _Mock:\n",
        "        def invoke(self, messages: List[Any]):\n",
        "            last_user = None\n",
        "            for m in reversed(messages):\n",
        "                if isinstance(m, HumanMessage):\n",
        "                    last_user = m\n",
        "                    break\n",
        "            return type(\"Obj\", (), {\"content\": \"[MOCK] \" + (last_user.content if last_user else \"\")})\n",
        "    print(\"Using mock LLM fallback\")\n",
        "    return _Mock()\n",
        "\n",
        "LLM = get_chat_model()\n",
        "\n",
        "# Optionally define system policy / prompt template\n",
        "SYSTEM_POLICY = (\n",
        "    \"You are ShopUNow Assistant. Be concise and accurate. Use the internal knowledge base when possible. \"\n",
        "    \"Cite sources. If you cannot answer, ask a clarifying question.\"\n",
        ")\n",
        "\n",
        "print(\"Cell A setup complete: vector_store and LLM are initialized.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIkC2RVqCKeo",
        "outputId": "2e5b469e-9057-4a94-fd0b-cdff9bb37e42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Gemini LLM\n",
            "Cell A setup complete: vector_store and LLM are initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell A.1 - Load FAQ Dataset & Build Vector Store\n",
        "# =========================\n",
        "import os\n",
        "import json\n",
        "import faiss\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# ---- Step 1: Choose JSONL path based on environment ----\n",
        "colab_path = \"/content/shopunow_faqs.jsonl\"\n",
        "repo_path = os.path.join(os.path.dirname(__file__), \"data\", \"shopunow_faqs.jsonl\") if \"__file__\" in globals() else \"shopunow_faqs.jsonl\"\n",
        "\n",
        "if os.path.exists(colab_path):\n",
        "    faq_path = colab_path\n",
        "elif os.path.exists(repo_path):\n",
        "    faq_path = repo_path\n",
        "else:\n",
        "    raise FileNotFoundError(\"❌ shopunow_faqs.jsonl not found in Colab or repo paths.\")\n",
        "\n",
        "# ---- Step 2: Load JSONL file ----\n",
        "faq_docs = []\n",
        "with open(faq_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:   # skip empty lines\n",
        "            continue\n",
        "        try:\n",
        "            record = json.loads(line)\n",
        "            question = record.get(\"question\", \"\").strip()\n",
        "            answer = record.get(\"answer\", \"\").strip()\n",
        "            dept = record.get(\"department\", \"unknown\").strip()\n",
        "\n",
        "            # Store Q + A in embeddings for better recall\n",
        "            combined_text = f\"Q: {question}\\nA: {answer}\"\n",
        "\n",
        "            faq_docs.append(\n",
        "                Document(\n",
        "                    page_content=combined_text,\n",
        "                    metadata={\n",
        "                        \"department\": dept,\n",
        "                        \"question\": question,\n",
        "                        \"answer\": answer\n",
        "                    }\n",
        "                )\n",
        "            )\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"⚠️ Skipping bad line: {line[:80]}... | Error: {e}\")\n",
        "\n",
        "print(f\"Loaded {len(faq_docs)} FAQs from {faq_path}\")\n",
        "\n",
        "# ---- Step 3: Build FAISS Vector Store ----\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "embedding_dim = len(embedding_model.embed_query(\"hello world\"))\n",
        "\n",
        "# Use cosine similarity (inner product)\n",
        "faiss_index = faiss.IndexFlatIP(embedding_dim)\n",
        "\n",
        "faq_vector_store = FAISS(\n",
        "    embedding_function=embedding_model,\n",
        "    index=faiss_index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={}\n",
        ")\n",
        "\n",
        "faq_ids = [f\"faq_{i+1}\" for i in range(len(faq_docs))]\n",
        "faq_vector_store.add_documents(documents=faq_docs, ids=faq_ids)\n",
        "\n",
        "print(f\"✅ Vector store built with {len(faq_docs)} FAQs \"\n",
        "      f\"across {len(set(d.metadata['department'] for d in faq_docs))} departments\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n48dlld5MHiC",
        "outputId": "0b2437ca-d9ce-4609-bbd3-a6683e0b7c64"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 119 FAQs from /content/shopunow_faqs.jsonl\n",
            "✅ Vector store built with 119 FAQs across 5 departments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell B - Agent Definition with JSONL Vector Store\n",
        "# (cosine sim + dept thresholds + tie-aware classifier + escalation & confidence)\n",
        "# =========================\n",
        "import json\n",
        "import faiss\n",
        "import numpy as np\n",
        "import random\n",
        "from typing import Optional, List, Dict, Any, Literal, Tuple\n",
        "from typing_extensions import Annotated\n",
        "from operator import add\n",
        "from pydantic import BaseModel, Field\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# --------------------\n",
        "# Determinism\n",
        "# --------------------\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# --------------------\n",
        "# Load JSONL FAQs\n",
        "# --------------------\n",
        "jsonl_path = \"/content/shopunow_faqs.jsonl\"\n",
        "faq_documents: List[Document] = []\n",
        "with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for raw in f:\n",
        "        raw = raw.strip()\n",
        "        if not raw:\n",
        "            continue\n",
        "        rec = json.loads(raw)\n",
        "        faq_documents.append(\n",
        "            Document(\n",
        "                page_content=rec[\"answer\"],\n",
        "                metadata={\n",
        "                    \"department\": rec.get(\"department\", \"unknown\"),\n",
        "                    \"question\": rec.get(\"question\", \"\")\n",
        "                }\n",
        "            )\n",
        "        )\n",
        "print(f\"Loaded {len(faq_documents)} FAQs from {jsonl_path}\")\n",
        "\n",
        "# --------------------\n",
        "# Embeddings (cosine)\n",
        "# --------------------\n",
        "class NormalizedOpenAIEmbeddings(OpenAIEmbeddings):\n",
        "    \"\"\"Normalize vectors so FAISS inner-product == cosine similarity.\"\"\"\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "        v = np.array(super().embed_query(text))\n",
        "        return (v / (np.linalg.norm(v) + 1e-10)).tolist()\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "        vs = np.array(super().embed_documents(texts))\n",
        "        return (vs / (np.linalg.norm(vs, axis=1, keepdims=True) + 1e-10)).tolist()\n",
        "\n",
        "embedding_model = NormalizedOpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "dim = len(embedding_model.embed_query(\"hello world\"))\n",
        "faiss_index = faiss.IndexFlatIP(dim)  # cosine via inner product\n",
        "\n",
        "faq_vector_store = FAISS(\n",
        "    embedding_function=embedding_model,\n",
        "    index=faiss_index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={}\n",
        ")\n",
        "\n",
        "faq_ids = [f\"faq_{i+1}\" for i in range(len(faq_documents))]\n",
        "faq_vector_store.add_documents(documents=faq_documents, ids=faq_ids)\n",
        "\n",
        "dept_count = len(set(d.metadata.get(\"department\", \"unknown\") for d in faq_documents))\n",
        "print(f\"✅ Vector store ready with {len(faq_documents)} documents across {dept_count} departments\")\n",
        "\n",
        "# --------------------\n",
        "# Sentiment\n",
        "# --------------------\n",
        "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def detect_sentiment(text: str) -> Literal[\"negative\",\"neutral\",\"positive\"]:\n",
        "    if not text:\n",
        "        return \"neutral\"\n",
        "    c = sentiment_analyzer.polarity_scores(text).get(\"compound\", 0.0)\n",
        "    if c <= -0.3: return \"negative\"\n",
        "    if c >= 0.3: return \"positive\"\n",
        "    return \"neutral\"\n",
        "\n",
        "# --------------------\n",
        "# Dept classifier with confidence & tie handling\n",
        "# --------------------\n",
        "DEPT_KEYWORDS: Dict[str, List[str]] = {\n",
        "    \"Orders & Returns\": [\n",
        "        \"order\", \"order status\", \"track order\", \"tracking\", \"shipment\",\n",
        "        \"delivery\", \"package\", \"where is my order\", \"cancel order\",\n",
        "        \"return\", \"refund\", \"replace\", \"exchange\", \"pickup\"\n",
        "    ],\n",
        "    \"Payments & Billing\": [\n",
        "        \"payment\", \"upi\", \"card\", \"wallet\", \"cod\", \"invoice\", \"coupon\",\n",
        "        \"billing\", \"charged\", \"charge\", \"emi\", \"price\", \"gst\"\n",
        "    ],\n",
        "    \"Customer Support\": [\n",
        "        \"support\", \"contact\", \"help\", \"issue\", \"complaint\", \"agent\",\n",
        "        \"human\", \"speak to\", \"phone\", \"call\", \"email\", \"hours\", \"timings\"\n",
        "    ],\n",
        "    \"HR & IT Helpdesk\": [\n",
        "        \"password\", \"vpn\", \"access\", \"onboarding\", \"hardware\", \"software\",\n",
        "        \"leave\", \"policy\", \"salary\", \"payroll\", \"payslip\", \"stipend\",\n",
        "        \"salary date\", \"pay date\", \"salary delayed\", \"hrms\", \"hr portal\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "def classify_department_with_confidence(user_query: str) -> Tuple[Optional[str], float, Dict[str, int]]:\n",
        "    text = (user_query or \"\").lower()\n",
        "    scores: Dict[str, int] = {}\n",
        "    for dept, kws in DEPT_KEYWORDS.items():\n",
        "        score = sum(1 for kw in kws if kw in text)\n",
        "        scores[dept] = score\n",
        "\n",
        "    # rank by score\n",
        "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_dept, top_score = sorted_scores[0]\n",
        "\n",
        "    # if nothing matched\n",
        "    if top_score == 0:\n",
        "        return None, 0.0, scores\n",
        "\n",
        "    # tie or near-tie? (within 1 point of second place)\n",
        "    if len(sorted_scores) > 1 and sorted_scores[1][1] >= top_score - 0.0:\n",
        "        # ambiguous — fall back to low confidence\n",
        "        return None, 0.0, scores\n",
        "\n",
        "    # confidence: cap small scores lower\n",
        "    # (simple heuristic: 1 feature → 0.6, 2 → 0.75, >=3 → 0.9)\n",
        "    conf = 0.6 if top_score == 1 else (0.75 if top_score == 2 else 0.9)\n",
        "    return top_dept, conf, scores\n",
        "\n",
        "# --------------------\n",
        "# Thresholds (cosine)\n",
        "# --------------------\n",
        "DEPT_SIM_THRESHOLDS = {\n",
        "    \"Orders & Returns\": 0.80,\n",
        "    \"Payments & Billing\": 0.78,\n",
        "    \"Customer Support\": 0.75,\n",
        "    \"HR & IT Helpdesk\": 0.70,\n",
        "    None: 0.80,  # default stricter if dept uncertain\n",
        "}\n",
        "\n",
        "# --------------------\n",
        "# Agent state\n",
        "# --------------------\n",
        "class AgentState(BaseModel):\n",
        "    user_input: str\n",
        "    department: Optional[str] = None\n",
        "    dept_confidence: float = 0.0\n",
        "    sentiment: Optional[Literal[\"negative\",\"neutral\",\"positive\"]] = None\n",
        "    tools_used: Annotated[List[str], add] = Field(default_factory=list)\n",
        "    retrieved: Annotated[List[Dict[str, Any]], add] = Field(default_factory=list)\n",
        "    intent: Optional[Literal[\"rag\",\"order_status\",\"return_create\",\"ticket\",\"human_escalation\",\"unknown\"]] = None\n",
        "    answer: Optional[str] = None\n",
        "    confidence: float = 0.0   # overall answer confidence\n",
        "    reason: Optional[str] = None  # why we escalated / confidence is low\n",
        "\n",
        "# --------------------\n",
        "# Helpers\n",
        "# --------------------\n",
        "def extract_answer_text(page_content: str) -> str:\n",
        "    \"\"\"If content is 'Q: ...\\\\nA: ...', return only the A: part.\"\"\"\n",
        "    if not page_content:\n",
        "        return page_content\n",
        "    lower = page_content.lower()\n",
        "    if \"a:\" in lower:\n",
        "        # take substring from first 'A:' onward (case-insensitive)\n",
        "        idx = lower.find(\"a:\")\n",
        "        return page_content[idx+2:].strip().lstrip(\":\").strip()\n",
        "    # fallback: if prefixed with 'Q:' then strip it\n",
        "    if page_content.strip().startswith(\"Q:\"):\n",
        "        return page_content.replace(\"Q:\", \"\", 1).strip()\n",
        "    return page_content\n",
        "\n",
        "def contains_any(text: str, keywords: List[str]) -> bool:\n",
        "    low = text.lower()\n",
        "    return any(kw in low for kw in keywords)\n",
        "\n",
        "# --------------------\n",
        "# Routing\n",
        "# --------------------\n",
        "def route_intent(state: AgentState) -> Dict[str, Any]:\n",
        "    user_query = state.user_input\n",
        "    query_lower = (user_query or \"\").lower()\n",
        "\n",
        "    sentiment = detect_sentiment(user_query)\n",
        "    dept, dept_conf, _scores = classify_department_with_confidence(user_query)\n",
        "\n",
        "    # If user is upset → escalate\n",
        "    if sentiment == \"negative\":\n",
        "        intent = \"human_escalation\"\n",
        "    # order status\n",
        "    elif contains_any(query_lower, [\n",
        "        \"order status\", \"track order\", \"where is my order\", \"tracking\",\n",
        "        \"shipment\", \"delivery\", \"package\"\n",
        "    ]):\n",
        "        intent = \"order_status\"\n",
        "    # returns / exchanges → either policy (RAG) or action (return_create)\n",
        "    elif contains_any(query_lower, [\"return\", \"refund\", \"replace\", \"exchange\"]):\n",
        "        if contains_any(query_lower, [\"policy\", \"how many\", \"days\", \"window\"]):\n",
        "            intent = \"rag\"\n",
        "        else:\n",
        "            intent = \"return_create\"\n",
        "    # tickets / complaints\n",
        "    elif contains_any(query_lower, [\"ticket\", \"helpdesk\", \"support issue\", \"complaint\", \"problem\"]):\n",
        "        intent = \"ticket\"\n",
        "    else:\n",
        "        intent = \"rag\"\n",
        "\n",
        "    print(f\"[route_intent] input={user_query!r} -> intent={intent}, dept={dept}, dept_conf={dept_conf:.2f}, sentiment={sentiment}\")\n",
        "    return {\"intent\": intent, \"department\": dept, \"dept_confidence\": dept_conf, \"sentiment\": sentiment}\n",
        "\n",
        "# --------------------\n",
        "# Tool node\n",
        "# --------------------\n",
        "def filter_by_department(results: List[Any], predicted_department: Optional[str]) -> List[Any]:\n",
        "    if not results:\n",
        "        return []\n",
        "    if predicted_department is None:\n",
        "        return results\n",
        "    filtered = [(doc, score) for doc, score in results\n",
        "                if (doc.metadata or {}).get(\"department\") == predicted_department]\n",
        "    return filtered or results\n",
        "\n",
        "def tool_node(state: AgentState) -> Dict[str, Any]:\n",
        "    intent = state.intent\n",
        "    user_query = state.user_input or \"\"\n",
        "    predicted_department = state.department\n",
        "    dept_conf = state.dept_confidence\n",
        "    print(f\"[tool_node] intent={intent}, dept={predicted_department}, dept_conf={dept_conf:.2f}, input={user_query!r}\")\n",
        "\n",
        "    # --- Direct tools ---\n",
        "    if intent == \"order_status\":\n",
        "        # Ask for Order ID if missing\n",
        "        has_order_id = any(tok.startswith((\"ORD-\", \"ord-\")) or tok.isdigit() for tok in user_query.replace(\"#\",\" \").split())\n",
        "        if not has_order_id:\n",
        "            return {\n",
        "                \"answer\": \"To check a specific order, please share your Order ID (e.g., ORD-1234).\",\n",
        "                \"tools_used\": [\"order_status_tool\"],\n",
        "                \"confidence\": 0.65,\n",
        "                \"reason\": \"order_id_missing\"\n",
        "            }\n",
        "        return {\n",
        "            \"answer\": \"Your order is being processed and will be shipped soon.\",\n",
        "            \"tools_used\": [\"order_status_tool\"],\n",
        "            \"confidence\": 0.9\n",
        "        }\n",
        "\n",
        "    if intent == \"return_create\":\n",
        "        return {\n",
        "            \"answer\": \"Return initiated. You will receive pickup and label details via email.\",\n",
        "            \"tools_used\": [\"return_create_tool\"],\n",
        "            \"confidence\": 0.9\n",
        "        }\n",
        "\n",
        "    if intent == \"ticket\":\n",
        "        return {\n",
        "            \"answer\": \"A support ticket has been created. Someone will get back to you shortly.\",\n",
        "            \"tools_used\": [\"ticket_tool\"],\n",
        "            \"confidence\": 0.85\n",
        "        }\n",
        "\n",
        "    if intent == \"human_escalation\":\n",
        "        return {\n",
        "            \"answer\": \"I’m sorry for the inconvenience. Escalating to human support — someone will reach out to you soon.\",\n",
        "            \"tools_used\": [\"escalation\"],\n",
        "            \"confidence\": 0.2,\n",
        "            \"reason\": \"negative_sentiment\"\n",
        "        }\n",
        "\n",
        "    # --- Retrieval (RAG) ---\n",
        "    if intent == \"rag\":\n",
        "        # Low dept confidence → escalate (ambiguous / multi-dept)\n",
        "        if not predicted_department or dept_conf < 0.6:\n",
        "            return {\n",
        "                \"answer\": \"Your query could relate to multiple areas. I’m escalating to human support to ensure it’s handled correctly.\",\n",
        "                \"tools_used\": [\"escalation\"],\n",
        "                \"confidence\": 0.2,\n",
        "                \"reason\": \"low_department_confidence\"\n",
        "            }\n",
        "        try:\n",
        "            results = faq_vector_store.similarity_search_with_score(user_query, k=5)\n",
        "            results = [(doc, score) for doc, score in results if doc is not None]\n",
        "            results = filter_by_department(results, predicted_department)\n",
        "\n",
        "            if not results:\n",
        "                return {\n",
        "                    \"answer\": \"Sorry, I couldn’t find reliable information in our knowledge base. Escalating to human support.\",\n",
        "                    \"tools_used\": [\"escalation\"],\n",
        "                    \"confidence\": 0.2,\n",
        "                    \"reason\": \"no_results\"\n",
        "                }\n",
        "\n",
        "            top_doc, cosine_sim = results[0]\n",
        "            print(f\"[tool_node] Top cosine similarity={cosine_sim:.4f}\")\n",
        "            sim_threshold = DEPT_SIM_THRESHOLDS.get(predicted_department, DEPT_SIM_THRESHOLDS[None])\n",
        "\n",
        "            if cosine_sim < sim_threshold:\n",
        "                # Optional fuzzy fallback — only if very high fuzzy match\n",
        "                best_doc, best_fuzzy = None, 0.0\n",
        "                for doc in faq_documents:\n",
        "                    fs = fuzz.partial_ratio(user_query.lower(), doc.metadata.get(\"question\",\"\").lower()) / 100.0\n",
        "                    if fs > best_fuzzy:\n",
        "                        best_doc, best_fuzzy = doc, fs\n",
        "                if best_doc and best_fuzzy >= 0.92:\n",
        "                    dept_meta = best_doc.metadata.get(\"department\", \"unknown\")\n",
        "                    clean_answer = extract_answer_text(best_doc.page_content)\n",
        "                    return {\n",
        "                        \"answer\": f\"{clean_answer} (Dept: {dept_meta})\",\n",
        "                        \"tools_used\": [\"rag_fuzzy_fallback\"],\n",
        "                        \"retrieved\": [{\"question\": best_doc.metadata.get(\"question\",\"\"),\n",
        "                                       \"answer\": clean_answer,\n",
        "                                       \"fuzzy_score\": float(best_fuzzy),\n",
        "                                       \"source\": dept_meta}],\n",
        "                        \"confidence\": float(min(0.85, best_fuzzy)),\n",
        "                        \"reason\": \"fuzzy_match_high\"\n",
        "                    }\n",
        "                return {\n",
        "                    \"answer\": \"I’m not fully confident about the answer. Escalating to human support.\",\n",
        "                    \"tools_used\": [\"escalation\"],\n",
        "                    \"confidence\": float(cosine_sim),\n",
        "                    \"reason\": \"low_similarity\"\n",
        "                }\n",
        "\n",
        "            # Passed threshold → return clean A: text\n",
        "            dept_meta = (top_doc.metadata or {}).get(\"department\", \"unknown\")\n",
        "            clean_answer = extract_answer_text(top_doc.page_content)\n",
        "            return {\n",
        "                \"answer\": f\"{clean_answer} (Dept: {dept_meta})\",\n",
        "                \"tools_used\": [\"rag_retrieval\"],\n",
        "                \"retrieved\": [{\"question\": top_doc.metadata.get(\"question\",\"\"),\n",
        "                               \"answer\": clean_answer,\n",
        "                               \"similarity\": float(cosine_sim),\n",
        "                               \"source\": dept_meta}],\n",
        "                \"confidence\": float(cosine_sim)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[tool_node] ❌ Retrieval error: {e}\")\n",
        "            return {\n",
        "                \"answer\": \"Something went wrong while searching. Escalating to human support.\",\n",
        "                \"tools_used\": [\"escalation\"],\n",
        "                \"confidence\": 0.0,\n",
        "                \"reason\": \"retrieval_exception\"\n",
        "            }\n",
        "\n",
        "    # Fallback\n",
        "    return {\n",
        "        \"answer\": \"Could you please rephrase your request?\",\n",
        "        \"tools_used\": [\"fallback\"],\n",
        "        \"confidence\": 0.3,\n",
        "        \"reason\": \"fallback\"\n",
        "    }\n",
        "\n",
        "# --------------------\n",
        "# Synthesis (no-op)\n",
        "# --------------------\n",
        "def synthesis_node(state: AgentState) -> Dict[str, Any]:\n",
        "    return {}\n",
        "\n",
        "# --------------------\n",
        "# Build Graph\n",
        "# --------------------\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "graph.add_node(\"route\", route_intent)\n",
        "graph.add_node(\"tool\", tool_node)\n",
        "graph.add_node(\"synth\", synthesis_node)\n",
        "\n",
        "graph.add_edge(START, \"route\")\n",
        "graph.add_edge(\"route\", \"tool\")\n",
        "graph.add_edge(\"tool\", \"synth\")\n",
        "graph.add_edge(\"synth\", END)\n",
        "\n",
        "memory = MemorySaver()\n",
        "app = graph.compile(checkpointer=memory)\n",
        "\n",
        "# --------------------\n",
        "# Ask wrapper (returns only text as before)\n",
        "# --------------------\n",
        "def ask(user_query: str, thread_id: Optional[str] = None) -> str:\n",
        "    if thread_id is None:\n",
        "        import uuid\n",
        "        thread_id = f\"thread_{uuid.uuid4().hex}\"\n",
        "    out = app.invoke({\"user_input\": user_query},\n",
        "                     config={\"configurable\": {\"thread_id\": thread_id}})\n",
        "    # out contains 'confidence' and 'reason' too if you need them in API\n",
        "    return out.get(\"answer\", \"No answer generated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18bhUnZECRuH",
        "outputId": "88a82411-b8c9-4dc2-dc20-f7c17dbd25d4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 119 FAQs from /content/shopunow_faqs.jsonl\n",
            "✅ Vector store ready with 119 documents across 5 departments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell B.1 - Testing (Improved Output & Meaningful Names)\n",
        "# =========================\n",
        "import uuid\n",
        "from pprint import pprint\n",
        "\n",
        "test_queries = [\n",
        "    \"What are your support hours?\",\n",
        "    \"Tell me order status for order id ORD-1234\",\n",
        "    \"I want a return because the product is wrong\",\n",
        "    \"My password reset isn't working, this is frustrating\",\n",
        "    \"I submitted a complaint about a support issue\",\n",
        "    \"How do I pay with UPI?\",\n",
        "    \"How to apply for leaves?\",\n",
        "    \"what is the leave policy?\",\n",
        "    \"where is my order?\",\n",
        "    \"my order is delayed\",\n",
        "    \"whats the return polcy? how many days can i return the product?\",\n",
        "    \"how many leaves can I take?\",\n",
        "    \" how many days for rturn?\",\n",
        "    \"my retturn is delayed\",\n",
        "    \"Please replace my shirt size\",\n",
        "    \"where is my order\",\n",
        "    \"when will i get my salary\",\n",
        "    \"my salaray is delayed\",\n",
        "    \"I need help,\",  # ambiguous\n",
        "]\n",
        "\n",
        "for user_query in test_queries:\n",
        "    # Create a fresh conversation ID for isolation\n",
        "    conversation_id = f\"conv_{uuid.uuid4().hex}\"\n",
        "    state = AgentState(user_input=user_query)\n",
        "\n",
        "    # Route intent & department\n",
        "    route_info = route_intent(state)\n",
        "\n",
        "    # Run through the graph (ask function)\n",
        "    response = app.invoke(\n",
        "        {\"user_input\": user_query},\n",
        "        config={\"configurable\": {\"thread_id\": conversation_id}}\n",
        "    )\n",
        "\n",
        "    # Print structured logs\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"🧑 User Query: {user_query}\")\n",
        "    print(f\"➡️ Intent: {route_info['intent']} | Dept: {route_info['department']} | Sentiment: {route_info['sentiment']}\")\n",
        "    print(f\"🤖 Agent Answer: {response.get('answer', '⚠️ No answer')}\")\n",
        "    print(f\"🛠️ Tools Used: {response.get('tools_used')}\")\n",
        "    if response.get(\"retrieved\"):\n",
        "        print(\"📄 Retrieved Context:\")\n",
        "        pprint(response[\"retrieved\"])\n",
        "    print(\"=\" * 80 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL6WcVgTCuGf",
        "outputId": "4b2a348c-cc59-4914-ba8e-734f4c3beac0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[route_intent] input='What are your support hours?' -> intent=rag, dept=Customer Support, dept_conf=0.75, sentiment=positive\n",
            "[route_intent] input='What are your support hours?' -> intent=rag, dept=Customer Support, dept_conf=0.75, sentiment=positive\n",
            "[tool_node] intent=rag, dept=Customer Support, dept_conf=0.75, input='What are your support hours?'\n",
            "[tool_node] Top cosine similarity=0.8049\n",
            "================================================================================\n",
            "🧑 User Query: What are your support hours?\n",
            "➡️ Intent: rag | Dept: Customer Support | Sentiment: positive\n",
            "🤖 Agent Answer: Yes, during business hours you can request 'Talk to a human' in chat. (Dept: Customer Support)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': \"Yes, during business hours you can request 'Talk to a human' in \"\n",
            "            'chat.',\n",
            "  'question': 'Can I chat with a human instead of a bot?',\n",
            "  'similarity': 0.8048972487449646,\n",
            "  'source': 'Customer Support'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='Tell me order status for order id ORD-1234' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[route_intent] input='Tell me order status for order id ORD-1234' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[tool_node] intent=order_status, dept=Orders & Returns, dept_conf=0.75, input='Tell me order status for order id ORD-1234'\n",
            "================================================================================\n",
            "🧑 User Query: Tell me order status for order id ORD-1234\n",
            "➡️ Intent: order_status | Dept: Orders & Returns | Sentiment: neutral\n",
            "🤖 Agent Answer: Your order is being processed and will be shipped soon.\n",
            "🛠️ Tools Used: ['order_status_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='I want a return because the product is wrong' -> intent=human_escalation, dept=Orders & Returns, dept_conf=0.60, sentiment=negative\n",
            "[route_intent] input='I want a return because the product is wrong' -> intent=human_escalation, dept=Orders & Returns, dept_conf=0.60, sentiment=negative\n",
            "[tool_node] intent=human_escalation, dept=Orders & Returns, dept_conf=0.60, input='I want a return because the product is wrong'\n",
            "================================================================================\n",
            "🧑 User Query: I want a return because the product is wrong\n",
            "➡️ Intent: human_escalation | Dept: Orders & Returns | Sentiment: negative\n",
            "🤖 Agent Answer: I’m sorry for the inconvenience. Escalating to human support — someone will reach out to you soon.\n",
            "🛠️ Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input=\"My password reset isn't working, this is frustrating\" -> intent=human_escalation, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=negative\n",
            "[route_intent] input=\"My password reset isn't working, this is frustrating\" -> intent=human_escalation, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=negative\n",
            "[tool_node] intent=human_escalation, dept=HR & IT Helpdesk, dept_conf=0.60, input=\"My password reset isn't working, this is frustrating\"\n",
            "================================================================================\n",
            "🧑 User Query: My password reset isn't working, this is frustrating\n",
            "➡️ Intent: human_escalation | Dept: HR & IT Helpdesk | Sentiment: negative\n",
            "🤖 Agent Answer: I’m sorry for the inconvenience. Escalating to human support — someone will reach out to you soon.\n",
            "🛠️ Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='I submitted a complaint about a support issue' -> intent=ticket, dept=Customer Support, dept_conf=0.90, sentiment=neutral\n",
            "[route_intent] input='I submitted a complaint about a support issue' -> intent=ticket, dept=Customer Support, dept_conf=0.90, sentiment=neutral\n",
            "[tool_node] intent=ticket, dept=Customer Support, dept_conf=0.90, input='I submitted a complaint about a support issue'\n",
            "================================================================================\n",
            "🧑 User Query: I submitted a complaint about a support issue\n",
            "➡️ Intent: ticket | Dept: Customer Support | Sentiment: neutral\n",
            "🤖 Agent Answer: A support ticket has been created. Someone will get back to you shortly.\n",
            "🛠️ Tools Used: ['ticket_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='How do I pay with UPI?' -> intent=rag, dept=Payments & Billing, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='How do I pay with UPI?' -> intent=rag, dept=Payments & Billing, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=Payments & Billing, dept_conf=0.60, input='How do I pay with UPI?'\n",
            "[tool_node] Top cosine similarity=0.8758\n",
            "================================================================================\n",
            "🧑 User Query: How do I pay with UPI?\n",
            "➡️ Intent: rag | Dept: Payments & Billing | Sentiment: neutral\n",
            "🤖 Agent Answer: At checkout, select UPI, click 'Add New ID', and complete verification. (Dept: Payments & Billing)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': \"At checkout, select UPI, click 'Add New ID', and complete \"\n",
            "            'verification.',\n",
            "  'question': 'How do I add a new UPI ID?',\n",
            "  'similarity': 0.875759482383728,\n",
            "  'source': 'Payments & Billing'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='How to apply for leaves?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='How to apply for leaves?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, input='How to apply for leaves?'\n",
            "[tool_node] Top cosine similarity=0.8792\n",
            "================================================================================\n",
            "🧑 User Query: How to apply for leaves?\n",
            "➡️ Intent: rag | Dept: HR & IT Helpdesk | Sentiment: neutral\n",
            "🤖 Agent Answer: You can apply for leave via the HRMS portal with manager approval. (Dept: HR & IT Helpdesk)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'You can apply for leave via the HRMS portal with manager '\n",
            "            'approval.',\n",
            "  'question': 'How to apply for leaves?',\n",
            "  'similarity': 0.8792254328727722,\n",
            "  'source': 'HR & IT Helpdesk'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='what is the leave policy?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.75, sentiment=neutral\n",
            "[route_intent] input='what is the leave policy?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.75, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=HR & IT Helpdesk, dept_conf=0.75, input='what is the leave policy?'\n",
            "[tool_node] Top cosine similarity=0.8282\n",
            "================================================================================\n",
            "🧑 User Query: what is the leave policy?\n",
            "➡️ Intent: rag | Dept: HR & IT Helpdesk | Sentiment: neutral\n",
            "🤖 Agent Answer: You can apply for leave via the HRMS portal with manager approval. (Dept: HR & IT Helpdesk)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'You can apply for leave via the HRMS portal with manager '\n",
            "            'approval.',\n",
            "  'question': 'How to apply for leaves?',\n",
            "  'similarity': 0.8281693458557129,\n",
            "  'source': 'HR & IT Helpdesk'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='where is my order?' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[route_intent] input='where is my order?' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[tool_node] intent=order_status, dept=Orders & Returns, dept_conf=0.75, input='where is my order?'\n",
            "================================================================================\n",
            "🧑 User Query: where is my order?\n",
            "➡️ Intent: order_status | Dept: Orders & Returns | Sentiment: neutral\n",
            "🤖 Agent Answer: To check a specific order, please share your Order ID (e.g., ORD-1234).\n",
            "🛠️ Tools Used: ['order_status_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='my order is delayed' -> intent=rag, dept=Orders & Returns, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='my order is delayed' -> intent=rag, dept=Orders & Returns, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=Orders & Returns, dept_conf=0.60, input='my order is delayed'\n",
            "[tool_node] Top cosine similarity=0.8718\n",
            "================================================================================\n",
            "🧑 User Query: my order is delayed\n",
            "➡️ Intent: rag | Dept: Orders & Returns | Sentiment: neutral\n",
            "🤖 Agent Answer: If your return is delayed, please check the order page or contact support for updates. (Dept: Orders & Returns)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'If your return is delayed, please check the order page or contact '\n",
            "            'support for updates.',\n",
            "  'question': 'My return is delayed',\n",
            "  'similarity': 0.8718098402023315,\n",
            "  'source': 'Orders & Returns'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='whats the return polcy? how many days can i return the product?' -> intent=rag, dept=Orders & Returns, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='whats the return polcy? how many days can i return the product?' -> intent=rag, dept=Orders & Returns, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=Orders & Returns, dept_conf=0.60, input='whats the return polcy? how many days can i return the product?'\n",
            "[tool_node] Top cosine similarity=0.8365\n",
            "================================================================================\n",
            "🧑 User Query: whats the return polcy? how many days can i return the product?\n",
            "➡️ Intent: rag | Dept: Orders & Returns | Sentiment: neutral\n",
            "🤖 Agent Answer: You can return items within 10 days of delivery for a full refund. (Dept: Orders & Returns)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'You can return items within 10 days of delivery for a full '\n",
            "            'refund.',\n",
            "  'question': 'What is the return policy?',\n",
            "  'similarity': 0.8364611864089966,\n",
            "  'source': 'Orders & Returns'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='how many leaves can I take?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='how many leaves can I take?' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, input='how many leaves can I take?'\n",
            "[tool_node] Top cosine similarity=0.8136\n",
            "================================================================================\n",
            "🧑 User Query: how many leaves can I take?\n",
            "➡️ Intent: rag | Dept: HR & IT Helpdesk | Sentiment: neutral\n",
            "🤖 Agent Answer: Employees can take up to 20 days of annual leave per year. Carryover is subject to approval. (Dept: HR & IT Helpdesk)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'Employees can take up to 20 days of annual leave per year. '\n",
            "            'Carryover is subject to approval.',\n",
            "  'question': 'How many leaves can I take?',\n",
            "  'similarity': 0.8135983943939209,\n",
            "  'source': 'HR & IT Helpdesk'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input=' how many days for rturn?' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[route_intent] input=' how many days for rturn?' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=None, dept_conf=0.00, input=' how many days for rturn?'\n",
            "================================================================================\n",
            "🧑 User Query:  how many days for rturn?\n",
            "➡️ Intent: rag | Dept: None | Sentiment: neutral\n",
            "🤖 Agent Answer: Your query could relate to multiple areas. I’m escalating to human support to ensure it’s handled correctly.\n",
            "🛠️ Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='my retturn is delayed' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[route_intent] input='my retturn is delayed' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=None, dept_conf=0.00, input='my retturn is delayed'\n",
            "================================================================================\n",
            "🧑 User Query: my retturn is delayed\n",
            "➡️ Intent: rag | Dept: None | Sentiment: neutral\n",
            "🤖 Agent Answer: Your query could relate to multiple areas. I’m escalating to human support to ensure it’s handled correctly.\n",
            "🛠️ Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='Please replace my shirt size' -> intent=return_create, dept=Orders & Returns, dept_conf=0.60, sentiment=positive\n",
            "[route_intent] input='Please replace my shirt size' -> intent=return_create, dept=Orders & Returns, dept_conf=0.60, sentiment=positive\n",
            "[tool_node] intent=return_create, dept=Orders & Returns, dept_conf=0.60, input='Please replace my shirt size'\n",
            "================================================================================\n",
            "🧑 User Query: Please replace my shirt size\n",
            "➡️ Intent: return_create | Dept: Orders & Returns | Sentiment: positive\n",
            "🤖 Agent Answer: Return initiated. You will receive pickup and label details via email.\n",
            "🛠️ Tools Used: ['return_create_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='where is my order' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[route_intent] input='where is my order' -> intent=order_status, dept=Orders & Returns, dept_conf=0.75, sentiment=neutral\n",
            "[tool_node] intent=order_status, dept=Orders & Returns, dept_conf=0.75, input='where is my order'\n",
            "================================================================================\n",
            "🧑 User Query: where is my order\n",
            "➡️ Intent: order_status | Dept: Orders & Returns | Sentiment: neutral\n",
            "🤖 Agent Answer: To check a specific order, please share your Order ID (e.g., ORD-1234).\n",
            "🛠️ Tools Used: ['order_status_tool']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='when will i get my salary' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[route_intent] input='when will i get my salary' -> intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=HR & IT Helpdesk, dept_conf=0.60, input='when will i get my salary'\n",
            "[tool_node] Top cosine similarity=0.7818\n",
            "================================================================================\n",
            "🧑 User Query: when will i get my salary\n",
            "➡️ Intent: rag | Dept: HR & IT Helpdesk | Sentiment: neutral\n",
            "🤖 Agent Answer: Payslips are available for download on the HR portal. (Dept: HR & IT Helpdesk)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'Payslips are available for download on the HR portal.',\n",
            "  'question': 'How do I access my payslip?',\n",
            "  'similarity': 0.7817860841751099,\n",
            "  'source': 'HR & IT Helpdesk'}]\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='my salaray is delayed' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[route_intent] input='my salaray is delayed' -> intent=rag, dept=None, dept_conf=0.00, sentiment=neutral\n",
            "[tool_node] intent=rag, dept=None, dept_conf=0.00, input='my salaray is delayed'\n",
            "================================================================================\n",
            "🧑 User Query: my salaray is delayed\n",
            "➡️ Intent: rag | Dept: None | Sentiment: neutral\n",
            "🤖 Agent Answer: Your query could relate to multiple areas. I’m escalating to human support to ensure it’s handled correctly.\n",
            "🛠️ Tools Used: ['escalation']\n",
            "================================================================================\n",
            "\n",
            "[route_intent] input='I need help,' -> intent=rag, dept=Customer Support, dept_conf=0.60, sentiment=positive\n",
            "[route_intent] input='I need help,' -> intent=rag, dept=Customer Support, dept_conf=0.60, sentiment=positive\n",
            "[tool_node] intent=rag, dept=Customer Support, dept_conf=0.60, input='I need help,'\n",
            "[tool_node] Top cosine similarity=0.7560\n",
            "================================================================================\n",
            "🧑 User Query: I need help,\n",
            "➡️ Intent: rag | Dept: Customer Support | Sentiment: positive\n",
            "🤖 Agent Answer: You can call our helpline at +91-XXXXXXXXXX during business hours. (Dept: Customer Support)\n",
            "🛠️ Tools Used: ['rag_retrieval']\n",
            "📄 Retrieved Context:\n",
            "[{'answer': 'You can call our helpline at +91-XXXXXXXXXX during business '\n",
            "            'hours.',\n",
            "  'question': 'How can I speak to a customer care representative?',\n",
            "  'similarity': 0.75599604845047,\n",
            "  'source': 'Customer Support'}]\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell C - Flask API with ngrok (collision-safe, deep debug, auto-reuse, frontend-sync)\n",
        "# =========================\n",
        "import os, sys, traceback, threading, uuid, socket\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "# --------- Flask Setup (separate var from LangGraph 'app') ---------\n",
        "flask_app = Flask(__name__)\n",
        "CORS(flask_app)\n",
        "\n",
        "def _debug(msg: str):\n",
        "    print(msg, flush=True)\n",
        "\n",
        "# --------- Agent Caller ---------\n",
        "def call_agent(query: str) -> str:\n",
        "    \"\"\"Call either ask() or a compiled LangGraph app if available.\"\"\"\n",
        "    if \"ask\" in globals() and callable(globals()[\"ask\"]):\n",
        "        _debug(\"[AGENT] Using ask()\")\n",
        "        return globals()[\"ask\"](query)\n",
        "\n",
        "    for name in [\"agent_app\", \"graph_app\", \"app\"]:\n",
        "        obj = globals().get(name)\n",
        "        if hasattr(obj, \"invoke\"):\n",
        "            _debug(f\"[AGENT] Using graph '{name}'.invoke()\")\n",
        "            cfg = {\"configurable\": {\"thread_id\": f\"api-{uuid.uuid4().hex}\"}}\n",
        "            out = obj.invoke({\"user_input\": query}, config=cfg)\n",
        "            return out.get(\"answer\", \"No answer generated.\")\n",
        "\n",
        "    raise RuntimeError(\"❌ No agent available. Run Cell B first.\")\n",
        "\n",
        "# --------- Routes ---------\n",
        "@flask_app.route(\"/ask\", methods=[\"POST\", \"GET\"])\n",
        "def ask_api():\n",
        "    try:\n",
        "        _debug(\"\\n[API] ▶️ Received /ask\")\n",
        "        if request.method == \"POST\":\n",
        "            if not request.is_json:\n",
        "                return jsonify({\"error\": \"Content-Type must be application/json\"}), 400\n",
        "            data = request.get_json(force=True, silent=True) or {}\n",
        "            query = (data.get(\"query\") or \"\").strip()\n",
        "        else:\n",
        "            query = (request.args.get(\"query\") or \"\").strip()\n",
        "\n",
        "        if not query:\n",
        "            return jsonify({\"error\": \"Empty query\"}), 400\n",
        "\n",
        "        _debug(f\"[API] Query: {query!r}\")\n",
        "        answer = call_agent(query)\n",
        "        _debug(f\"[API] ✅ Answer: {answer!r}\")\n",
        "        return jsonify({\"query\": query, \"answer\": answer})\n",
        "\n",
        "    except Exception as e:\n",
        "        _debug(\"[API] ❌ Internal server error\")\n",
        "        traceback.print_exc(file=sys.stdout)\n",
        "        return jsonify({\"error\": \"Internal server error\", \"details\": str(e)}), 500\n",
        "\n",
        "@flask_app.route(\"/\", methods=[\"GET\"])\n",
        "def home():\n",
        "    return jsonify({\"status\": \"ok\", \"message\": \"ShopUNow Agent API is running!\"})\n",
        "\n",
        "# --------- Run Flask (dynamic port, avoids collisions) ---------\n",
        "def find_free_port(default=5000):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.bind((\"\", 0))\n",
        "        return s.getsockname()[1]\n",
        "\n",
        "PORT = find_free_port(5000)\n",
        "_debug(f\"▶️ Starting Flask server on port {PORT}...\")\n",
        "\n",
        "def run_flask():\n",
        "    try:\n",
        "        flask_app.run(host=\"0.0.0.0\", port=PORT, debug=False, use_reloader=False)\n",
        "    except Exception as e:\n",
        "        _debug(f\"❌ Flask crashed: {e}\")\n",
        "        traceback.print_exc(file=sys.stdout)\n",
        "\n",
        "threading.Thread(target=run_flask, daemon=True).start()\n",
        "\n",
        "# --------- ngrok setup ---------\n",
        "try:\n",
        "    from pyngrok import ngrok\n",
        "except ImportError:\n",
        "    _debug(\"[NGROK] Installing pyngrok...\")\n",
        "    import subprocess\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyngrok\"], check=True)\n",
        "    from pyngrok import ngrok\n",
        "\n",
        "def _get_secret(name):\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        return userdata.get(name)\n",
        "    except Exception:\n",
        "        return os.getenv(name)\n",
        "\n",
        "NGROK_AUTH_TOKEN = _get_secret(\"NGROK_AUTH_TOKEN\")\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    _debug(\"🔑 Setting ngrok auth token\")\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "else:\n",
        "    _debug(\"⚠️ No ngrok auth token found; using free session\")\n",
        "\n",
        "# Kill old tunnels before opening a new one\n",
        "ngrok.kill()\n",
        "\n",
        "try:\n",
        "    _debug(f\"🌐 Starting ngrok tunnel on :{PORT} ...\")\n",
        "    tunnel = ngrok.connect(PORT)\n",
        "    public_url = getattr(tunnel, \"public_url\", str(tunnel))\n",
        "    _debug(f\"🚀 Public API URL: {public_url}\")\n",
        "\n",
        "    # ---- Write URL for frontend auto-detection ----\n",
        "    backend_file = \"/content/backend_url.txt\"\n",
        "    with open(backend_file, \"w\") as f:\n",
        "        f.write(public_url.strip())\n",
        "    _debug(f\"📂 Saved backend URL to {backend_file}\")\n",
        "\n",
        "    # Print curl test\n",
        "    print(\"\\nTest with:\")\n",
        "    print(f'curl -X POST \"{public_url}/ask\" -H \"Content-Type: application/json\" -d \"{{\\\\\"query\\\\\": \\\\\"What are your support hours?\\\\\"}}\"')\n",
        "except Exception as e:\n",
        "    _debug(f\"❌ ngrok connection failed: {e}\")\n",
        "    traceback.print_exc(file=sys.stdout)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgBZx70SRRCQ",
        "outputId": "98c7bf0e-2c9e-449a-8162-9f8bc062ac6e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ Starting Flask server on port 33727...\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:33727\n",
            " * Running on http://172.28.0.12:33727\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔑 Setting ngrok auth token\n",
            "🌐 Starting ngrok tunnel on :33727 ...\n",
            "🚀 Public API URL: https://f05fcbc10c57.ngrok-free.app\n",
            "📂 Saved backend URL to /content/backend_url.txt\n",
            "\n",
            "Test with:\n",
            "curl -X POST \"https://f05fcbc10c57.ngrok-free.app/ask\" -H \"Content-Type: application/json\" -d \"{\\\"query\\\": \\\"What are your support hours?\\\"}\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Cell D - Streamlit Frontend (Auto-detect backend, Mandatory Keys, LangSmith optional)\n",
        "# =========================\n",
        "import subprocess, threading, os\n",
        "\n",
        "!pip install -q streamlit requests pyngrok\n",
        "\n",
        "# Try to auto-read backend URL from file\n",
        "backend_url_file = \"/content/backend_url.txt\"\n",
        "default_api_url = \"http://127.0.0.1:5000/ask\"\n",
        "if os.path.exists(backend_url_file):\n",
        "    try:\n",
        "        with open(backend_url_file, \"r\") as f:\n",
        "            url = f.read().strip()\n",
        "            if url:\n",
        "                default_api_url = url.rstrip(\"/\") + \"/ask\"\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Could not read backend_url.txt:\", e)\n",
        "\n",
        "with open(\"app_frontend.py\", \"w\") as f:\n",
        "    f.write(f\"\"\"\n",
        "import streamlit as st\n",
        "import requests\n",
        "\n",
        "st.set_page_config(page_title=\"ShopUNow Agent\", page_icon=\"🛍️\", layout=\"centered\")\n",
        "st.title(\"🛍️ ShopUNow AI Assistant\")\n",
        "\n",
        "# --- Sidebar: Configuration ---\n",
        "st.sidebar.header(\"🔑 Configuration (Required)\")\n",
        "\n",
        "api_url = st.sidebar.text_input(\"Flask API URL (auto-detected from backend)\", value=\"{default_api_url}\")\n",
        "openai_key = st.sidebar.text_input(\"OpenAI API Key\", type=\"password\")\n",
        "gemini_key = st.sidebar.text_input(\"Gemini API Key\", type=\"password\")\n",
        "ngrok_token = st.sidebar.text_input(\"ngrok Auth Token\", type=\"password\")\n",
        "\n",
        "st.sidebar.header(\"Optional\")\n",
        "langsmith_key = st.sidebar.text_input(\"LangSmith Key (optional)\", type=\"password\")\n",
        "\n",
        "# ---- Validation ----\n",
        "errors = []\n",
        "if not api_url.strip():\n",
        "    errors.append(\"❌ Flask API URL is required.\")\n",
        "if not (openai_key.strip() or gemini_key.strip()):\n",
        "    errors.append(\"❌ At least one model key (OpenAI or Gemini) is required.\")\n",
        "if not ngrok_token.strip():\n",
        "    errors.append(\"❌ ngrok Auth Token is required.\")\n",
        "\n",
        "if errors:\n",
        "    for e in errors:\n",
        "        st.sidebar.error(e)\n",
        "    st.stop()\n",
        "else:\n",
        "    st.sidebar.success(\"✅ All required configuration set\")\n",
        "\n",
        "# Store secrets\n",
        "st.session_state.secrets = {{\n",
        "    \"API_URL\": api_url.strip(),\n",
        "    \"OPENAI_API_KEY\": openai_key.strip(),\n",
        "    \"GEMINI_API_KEY\": gemini_key.strip(),\n",
        "    \"NGROK_AUTH_TOKEN\": ngrok_token.strip(),\n",
        "    \"LANGSMITH_KEY\": langsmith_key.strip(),\n",
        "}}\n",
        "\n",
        "# --- Chat Section ---\n",
        "st.subheader(\"💬 Chat with ShopUNow Agent\")\n",
        "\n",
        "if \"chat\" not in st.session_state:\n",
        "    st.session_state.chat = []\n",
        "\n",
        "query = st.text_input(\"Type your question here:\")\n",
        "\n",
        "if st.button(\"Ask\"):\n",
        "    if query.strip():\n",
        "        st.session_state.chat.append((\"🧑 You\", query))\n",
        "        try:\n",
        "            resp = requests.post(st.session_state.secrets[\"API_URL\"], json={{\"query\": query}}, timeout=20)\n",
        "            if resp.status_code == 200:\n",
        "                data = resp.json()\n",
        "                answer = data.get(\"answer\", \"⚠️ No answer returned\")\n",
        "            else:\n",
        "                answer = f\"⚠️ Error {{resp.status_code}}: {{resp.text}}\"\n",
        "        except Exception as e:\n",
        "            answer = f\"⚠️ Request failed: {{e}}\"\n",
        "\n",
        "        st.session_state.chat.append((\"🤖 Agent\", answer))\n",
        "\n",
        "# --- Display chat history ---\n",
        "for sender, msg in st.session_state.chat:\n",
        "    st.markdown(f\"**{{sender}}:** {{msg}}\")\n",
        "\"\"\")\n",
        "\n",
        "# ---- Run Streamlit in background ----\n",
        "def run_streamlit():\n",
        "    subprocess.run(\n",
        "        [\"streamlit\", \"run\", \"app_frontend.py\", \"--server.port\", \"8501\", \"--server.headless\", \"true\"]\n",
        "    )\n",
        "\n",
        "threading.Thread(target=run_streamlit, daemon=True).start()\n",
        "\n",
        "# ---- ngrok tunnel for frontend ----\n",
        "from pyngrok import ngrok\n",
        "print(\"🌐 Starting ngrok tunnel for Streamlit...\")\n",
        "frontend_url = ngrok.connect(8501)\n",
        "print(\"🚀 Streamlit Frontend URL:\", frontend_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgocOgNHW72d",
        "outputId": "67f6f818-4bb1-4fb0-f49b-443cfede9235"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-09-21T15:15:08+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌐 Starting ngrok tunnel for Streamlit...\n",
            "🚀 Streamlit Frontend URL: NgrokTunnel: \"https://3cc7895cb13d.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}